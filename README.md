#  개요   

C를 이용한 Tcp / Ip Socket 프로그래밍 연습입니다.
윈도우 운영체제 환경에서 작업하였습니다.  


### 소스를 돌리기 위해 Visual Studio 상에서 다음 작업을 합니다.


1. 프로젝트 -> 속성 -> 구성 속성 -> 링커 -> 입력 -> 추가 종속성 -> ws2_32.lib 추가   


2. 프로젝트 -> 속성 -> 구성 속성 -> C/C++ -> 일반 -> SDL 검사 -> 아니오 체크   


3. Debug -> Release 모드로 변경(실행파일을 만들기 위함)   


4. cmd에서 Release 폴더로 이동한 후에 `실행파일명 포트번호` 입력      
   
   
   #
# 네트워크 프로그래밍과 소켓   

네트워크로 연결되어 있는 서로 다른 두 컴퓨터가 데이터를 주고받을 수 있도록 하는 것이 `네트워크 프로그래밍`이다.    

프로그래머의 입장에서 이미 대부분의 컴퓨터가 인터넷이라는 거대한 네트워크로 연결되어 있으니,
물리적인 연결은 신경 쓸 필요가 없다.   

때문에 이 물리적인 연결을 기반으로 하는 소프트웨어적인 데이터의 송수신 방법만 고민하면 된다.   
그런데 이 역시도 고민할 필요가 없다.   

운영체제에서 `소켓(Socket)`이라는 것을 제공하기 때문이다.   
이는 물리적으로 연결된 네트워크상에서의 데이터 송수신에 사용할 수 있는 소프트웨어적인 장치를 의미한다.   
때문에 데이터 송수신의 원리를 이론적으로 잘 몰라도, 소켓이라는 것을 이용해서 데이터를 주고 받을 수 있다.   
그래서 네트워크 프로그래밍을 `소켓 프로그래밍`이라고도 한다.   

정리하자면, 프로그래밍에서의 `소켓`은 네트워크 망의 연결에 사용하는 도구이다.   
`소켓`은 네트워크를 통한 두 컴퓨터의 연결을 의미하기도 한다.      
   
   
   #
# 서버 소켓의 개요   

- 1단계. 소켓 생성 `socket` 함수 호출   
- 2단계. IP주소와 PORT번호 할당 `bind` 함수 호출   
- 3단계. 연결요청 가능상태로 변경 `listen` 함수 호출   
- 4단계. 연결요청에 대한 수락 `accept` 함수 호출      
   
   
   #
# 리눅스 기반 파일 조작하기   

리눅스는 소켓을 파일의 일종으로 구분한다.   
따라서 파일 입출력 함수를 소켓 입출력에, 다시 말해서 네트워크상에서의 데이터 송수신에 사용할 수 있다.      


### 파일 디스크립터   

파일 디스크립터란 시스템으로부터 할당 받은 파일 또는 소켓에 부여된 정수를 의미한다.      


### 파일 열기   

`int open(char *path, int flag);`   

- path : 파일 이름을 나타내는 문자열의 주소 값 전달.   
- flag : 파일의 오픈 모드 정보 전달.   
- 성공 시 파일 디스크립터, 실패 시 -1 반환      


### 파일 닫기   

`int close(int fd);`   

- fd : 닫고자 하는 파일 또는 소켓의 파일 디스크립터 전달.   
- 성공 시 0, 실패 시 -1 반환      


### 파일에 데이터 쓰기   

`ssize_t write(int fd, const void * buf, size_t nbytes);`   

- fd : 데이터 전송 대상을 나타내는 파일 디스크립터 전달.   
- buf : 전송할 데이터가 저장된 버퍼의 주소 값 전달.   
- nbytes : 전송할 데이터의 바이트 수 전달.   
- 성공 시 전달한 바이트 수, 실패 시 -1 반환      


### 파일에 저장된 데이터 읽기   

`ssize_t read(int fd, void *buf, size_t nbytes);`   

- fd : 데이터 수신 대상을 나타내는 파일 디스크립터 전달.   
- buf : 수신한 데이터를 저장할 버퍼의 주소 값 전달.   
- nbytes : 수신할 최대 바이트 수 전달.   
- 성공 시 수신한 바이트 수(단, 파일의 끝을 만나면 0), 실패 시 -1 반환      
   
   
   #
# 윈도우 기반의 서버 소켓 관련 함수   


### 윈속(winsock)의 초기화   

윈속 프로그래밍을 할 때에는 반드시 `WSAStartup` 함수를 호출해서,   
프로그램에서 요구하는 윈도우 소켓의 버전을 알리고,   
해당 버전을 지원하는 라이브러리의 초기화 작업을 진행해야 한다.      

`int WSAStartup(WORD wVersionRequested, LPWSADATA lpWSAData);`   

- wVersionRequested : 프로그래머가 사용할 윈속의 버전정보 전달.   
- lpWSAData : WSADATA라는 구조체 변수의 주소 값 전달.   
- 성공 시 0, 실패 시 0이 아닌 에러코드 값 반환   

위의 함수를 호출하는 아래의 코드는 윈속 기반의 프로그래밍에서는 공식과 같이 등장한다.      

<pre>
<code>
int main(int argc, char* argv[]) {   

  WSADATA wsaData;

  ...
   
  if(WSAStartup(MAKEWORD(2, 2), &wsaData) != 0) ErrorHandling("WSAStartup() error!");
  
  ...
   
  return 0;   
}   
</code>
</pre>
   
다음은 위의 윈속 라이브러리의 해제에 사용되는 함수이다.   

`int WSACleanup(void);`   

- 성공 시 0, 실패 시 SOCKET_ERROR 반환      


### 소켓 생성   

`SOCKET socket(int af, int type, int protocol);`   

- 성공 시 소켓 핸들, 실패 시 INVALID_SOCKET 반환   


### IP주소와 PORT번호 할당   

`int bind(SOCKET s, const struct sockaddr * name, int namelen);`   

- 성공 시 소켓 핸들, 실패 시 SOCKET_ERROR 반환   


### 연결 요청 가능 상태로 변경   

`int listen(SOCKET s, int backlog);`   

- 성공 시 0, 실패 시 SOCKET_ERROR 반환   


### 연결 요청에 대한 수락   

`SOCKET accept(SOCKET s, struct sockaddr * addr, int * addrlen);`   

- 성공 시 소켓 핸들, 실패 시 INVALID_SOCKET 반환   
   
   
   #
# 윈도우 기반의 클라이언트 소켓 관련 함수   

### 서버로의 연결 요청   

`int connect(SOCKET s, const struct sockaddr * name, int namelen);`   

- 성공 시 0, 실패 시 SOCKET_ERROR 반환   

### 소켓 연결 닫기   

리눅스에서는 파일을 닫을 때에도, 소켓을 닫을 때에도 `close` 함수를 호출하지만,   
윈도우에서는 소켓을 닫을 때 호출하는 다음 함수가 별도로 마련되어 있다.   

`int closesocket(SOCKET s);`   

- 성공 시 0, 실패 시 SOCKET_ERROR 반환   
   
   
   #
# 윈도우 기반 입출력 함수   

리눅스는 소켓도 파일로 간주하기 때문에, 파일 입출력 함수인 `read`와 `write`를 이용해서 데이터를 송수신할 수 있다.   
그러나 윈도우는 상황이 좀 다르다.   
파일 입출력 함수와 소켓 입출력 함수가 엄연히 구분되기 때문이다.   
다음은 윈도우 소켓 기반의 데이터 입출력 함수이다.   

### 데이터 보내기   

`int send(SOCKET s, const char * buf, int len, int flags);`   

- s : 데이터 전송 대상과의 연결을 의미하는 소켓의 핸들 값 전달.   
- buf : 전송할 데이터를 저장하고 있는 버퍼의 주소 값 전달.   
- len : 전송할 바이트 수 전달.   
- flags : 데이터 전송 시 적용할 다양한 옵션 정보 전달.   
- 성공 시 전송된 바이트 수, 실패 시 SOCKET_ERROR 반환   

### 데이터 읽기   

`int recv(SOCKET s, const char * buf, int len, int flags);`   

- s : 데이터 수신 대상과의 연결을 의미하는 소켓의 핸들 값 전달.   
- buf : 수신된 데이터를 저장할 버퍼의 주소 값 전달.   
- len : 수신할 수 있는 최대 바이트 수 전달.   
- flags : 데이터 수신 시 적용할 다양한 옵션 정보 전달.   
- 성공 시 수신한 바이트 수(단 EOF 전송 시 0), 실패 시 SOCKET_ERROR 반환   
   
   
   #
# 소켓의 프로토콜과 그에 따른 데이터 전송 특성   

### 프로토콜(Protocol)이란 무엇인가?   

프로토콜이란 대화에 필요한 통신규약을 의미한다.   
그리고 이러한 프로토콜의 개념은 컴퓨터의 관점에서 다음과 같이 정리할 수 있다.   

`컴퓨터 상호간의 대화에 필요한 통신규약`   

쉽게 말해서 프로토콜은 약속이다.   
서로 데이터를 주고받기 위해서 정의해 놓은 약속을 뜻한다.   

### 소켓의 생성   

`int socket(int domain, int type, int protocol);`   

- domain : 소켓이 사용할 프로토콜 체계(Protocol Family) 정보 전달.   
- type : 소켓의 데이터 전송방식에 대한 정보 전달.   
- protocol : 두 컴퓨터간 통신에 사용되는 프로토콜 정보 전달.   

### 프로토콜 체계(Protocol Family)   

- PF_INET : IPv4 인터넷 프로토콜 체계   
- PF_INET6 : IPv6 인터넷 프로토콜 체계   
- PF_LOCAL : 로컬 통신을 위한 UNIX 프로토콜 체계   
- PF_PACKET : Low Level 소켓을 위한 프로토콜 체계   
- PF_IPX : IPX 노벨 프로토콜 체계   

현재 아직까지 대부분 PF_INET 프로토콜 체계를 이용해 소켓 프로그래밍을 한다.   

### 소켓의 타입(Type)   

프로토콜 체계(Protocol Family)가 결정되었다고 해서 데이터의 전송방식까지 완전히 결정되는 것은 아니다.   
즉, socket 함수의 첫 번째 인자로 전달되는 `PF_INET`에 해당하는 프로토콜 체계에도 둘 이상의 데이터 전송방식이 존재한다.   
다음은 IPv4 인터넷 프로토콜 체계에서 사용되는 대표적인 데이터 전송방식 두 가지이다.   

### 연결지향형 소켓(SOCK_STREAM) - TCP   

연결지향형 프로토콜인 `TCP`는 다음의 특성을 지닌다.   

- 중간에 데이터가 소멸되지 않고 목적지로 전송된다.
	- 자신과 연결된 상대 소켓의 상태를 파악해가면서 데이터를 전송한다.   
	혹 데이터가 제대로 전송되지 않으면 데이터를 재전송하기까지 한다.   
- 전송 순서대로 데이터가 수신된다.   
- 전송되는 데이터의 경계(Boundary)가 존재하지 않는다.
	- 데이터를 송수신하는 소켓은 내부적으로 버퍼(buffer), 쉽게 말해서 바이트 배열을 지니고 있다.   
	그리고 소켓을 통해 전송되는 데이터는 일단 이 배열에 저장된다.   
	때문에 데이터가 수신되었다고 해서 바로 read 함수를 호출해야 하는 것은 아니다.   
	이 배열의 용량을 초과하지 않는 한, 데이터가 채워진 후에 한 번의 read 함수 호출을 통해서 데이터 전부를 읽어 들일 수도 있고,   
	반대로 한 번의 write 함수 호출로 전송된 데이터 전부를 여러 번의 read 함수 호출을 통해서 읽어 들일 수도 있다.   
	즉, read 함수의 호출 횟수와 write 함수의 호출 횟수는 연결지향형 소켓의 경우 큰 의미를 갖지 못한다.   
	때문에, 연결지향형 소켓은 데이터의 경계가 존재하지 않는다고 말하는 것이다.   

### 비 연결지향형 소켓(SOCK_DGRAM) - UDP   

비 연결지향형 프로토콜인 `UDP`는 다음의 특성을 지닌다.   

- 전송된 순서에 상관없이 가장 빠른 전송을 지향한다.   

- 전송된 데이터는 손실의 우려가 있고, 파손의 우려가 있다.   

- 전송되는 데이터의 경계(Boundary)가 존재한다.   

- 한 번에 전송할 수 있는 데이터의 크기가 제한된다.   
   
   
   #
# 소켓에 할당되는 IP 주소와 PORT 번호   

### IP와 PORT   

IP는 Internet Protocol의 약자로 인터넷상에서 데이터를 송수신할 목적으로 컴퓨터에게 부여하는 값을 의미한다.   
반면 PORT 번호는 컴퓨터에게 부여하는 값이 아닌, 프로그램상에서 생성되는 소켓을 구분하기 위해 소켓에 부여되는 번호를 뜻한다.   

### 인터넷 주소(Internet Address)   

인터넷에 컴퓨터를 연결해서 데이터를 주고받기 위해서는 IP 주소를 부여 받아야 한다.   
이러한 IP 주소체계는 다음과 같이 두 종류로 나뉜다.   

- IPv4(Internet Protocol version 4) : 4바이트 주소체계   
- IPv6(Internet Protocol version 6) : 16바이트 주소체계   

IPv4와 IPv6의 차이점은 IP 주소의 표현에 사용되는 바이트 크기에 있다.   
오늘날 우리가 범용적으로 사용하는 주소체계는 IPv4이다.   
IPv6는 IPv4 체계의 주소가 모두 고갈될 일을 염려하여 만들어진 표준인데, 아직은 IPv4가 주로 사용되고 있다.   
   
IPv4 기준의 4바이트 IP 주소는 네트워크 주소와 호스트(컴퓨터를 의미함) 주소로 나뉘며,   
주소의 형태에 따라서 A, B, C, D, E 클래스로 분류가 된다.   
다음 그림은 IPv4의 주소체계를 보여준다.   
   
![네트워크 클래스](https://user-images.githubusercontent.com/46395776/97806351-98dd9100-1c9e-11eb-917e-12358b5ed7b0.png)   
   
네트워크 주소(네트워크 ID)란 네트워크의 구분을 위한 IP 주소의 일부를 말한다.   
해당 네트워크 주소로 우선 데이터를 전송한 후,   
호스트 ID를 참조하여 해당 네트워크 내의 호스트(PC)로 데이터를 최종 전달하는 것이다.   

### 소켓의 구분에 활용되는 PORT 번호   

IP는 컴퓨터를 구분하기 위한 목적으로 존재한다.   
때문에, IP만 있다면 목적지 컴퓨터로 데이터를 전송할 수는 있다.   
그러나 이것만 가지고 데이터를 수신해야 하는 최종 목적지인 응용프로그램(애플리케이션)까지 데이터를 전송할 순 없다.   
   
대부분의 컴퓨터에는 `NIC(네트워크 인터페이스 카드)`라 불리는 데이터 송수신장치가 하나씩 달려있다.   
IP는 데이터를 NIC를 통해 컴퓨터 내부로 전송하는데 사용된다.   
그러나 컴퓨터 내부로 전송된 데이터를 소켓에 적절히 분배하는 작업은 운영체제가 담당한다.   
이 때, 운영체제는 PORT 번호를 활용한다.   
즉, NIC를 통해서 수신된 데이터 안에는 PORT 번호가 새겨져 있다.   
운영체제는 바로 이 정보를 참조해서 일치하는 PORT 번호의 소켓에 데이터를 전달하는 것이다.   
   
이렇듯 PORT 번호는 하나의 운영체제 내에서 소켓을 구분하는 목적으로 사용되기 때문에, 하나의 운영체제 내에서 동일한 PORT 번호를 둘 이상의 소켓에 할당할 수 없다.   
그리고 PORT 번호는 16비트로 표현된다.   
때문에, 할당할 수 있는 PORT의 범위는 0 ~ 65535이다.   
그러나 0부터 1023번까지는 `잘 알려진 PORT(Well-known PORT)`라 해서, 특정 프로그램에 할당하기로 예약되어있기 때문에,   
이 범위의 값을 제외한 다른 값을 할당해야 한다.   
   
   
   #
# 네트워크 바이트 순서와 인터넷 주소 변환   

### 바이트 순서(Order)와 네트워크 바이트 순서   

CPU에 따라서 4바이트 정수 1을 메모리공간에 저장하는 방식이 달라질 수 있다.   
4바이트 정수 1을 2진수로 표현하면 다음과 같다.   
   
`00000000 00000000 00000000 00000001`   
   
이 순서 그대로 메모리에 저장하는 CPU가 있는가 하면, 다음과 같이 거꾸로 저장하는 CPU도 있다.   
   
`00000001 00000000 00000000 00000000`   
   
때문에, 이러한 부분을 고려하지 않고서 데이터를 송수신하면 문제가 발생할 수 있다.   
저장순서가 다르다는 것은 전송되어 온 데이터의 해석 순서가 다름을 뜻하기 때문이다.   
   
CPU가 데이터를 메모리에 저장하는 방식은 다음과 같이 두 가지로 나뉜다.   
참고로 CPU가 데이터를 메모리에 저장하는 방식이 두 가지로 나뉜다는 것은 CPU가 데이터를 해석하는 방식도 두 가지로 나뉜다는 뜻이다.   
   
- 빅 엔디안(Big Endian) : 상위 바이트의 값을 작은 번지수에 저장하는 방식   
- 리틀 엔디안(Little Endian) : 상위 바이트의 값을 큰 번지수에 저장하는 방식   

예를 들어, 0x1000번지를 시작으로 4바이트 int형 정수 0x12345678을 저장한다고 가정해 보자.   
그러면 다음 그림과 같이 저장된다.   
   
![엔디안](https://user-images.githubusercontent.com/46395776/97808170-b1eb3f80-1ca8-11eb-9b18-c94df0226025.jpeg)   
   
이렇게 CPU마다 차이나는 바이트 순서는 호스트끼리 데이터 전송 시에 문제가 된다.   
바로 이러한 문제점 때문에 네트워크를 통해서 데이터를 전송할 때에는 통일된 기준으로 데이터를 전송하기로 약속했으며,   
이 약석을 가리켜 `네트워크 바이트 순서(Network Byte Order)`라 한다.   
네트워크 바이트 순서의 약속은 매우 간단하다.   
   
`빅 엔디안 방식으로 통일하자!`   
   
즉, 네트워크상으로 데이터를 전송할 때에는 데이터의 배열을 빅 엔디안 기준으로 변경해서 송수신하기로 약속한 것이다.   
때문에, 모든 컴퓨터는 수신된 데이터가 네트워크 바이트 순서로 정렬되어 있음을 인식해야 하며,   
리틀 엔디안 시스템에서는 데이터를 전송하기에 앞서 빅 엔디안의 정렬방식으로 데이터를 재정렬해야 한다.   

### INADDR_ANY   

서버 소켓의 생성과정에서 매번 서버의 IP 주소를 입력하는 것은 귀찮은 일이 될 수 있다.   
그렇다면 다음과 같이 주소 정보를 초기화해도 된다.   
   
<pre>
<code>

struct sockaddr_in addr;
char *serv_port = "9190";
memset(&addr, 0, sizeof(addr));
addr.sin_family = AF_INET;
addr.sin_addr.s_addr = htonl(INADDR_ANY);
addr.sin_port = htons(atoi(serv_port));

</code>
</pre>   
   
위의 코드에서 INADDR_ANY라는 이름의 상수를 통해서 서버의 IP 주소를 할당하고 있다.   
소켓의 IP 주소를 이렇게 초기화할 경우, 소켓이 동작하는 컴퓨터의 IP 주소가 자동으로 할당되기 때문에 IP 주소를 직접 입력하는 수고를 덜 수 있다.   
뿐만 아니라, 컴퓨터 내에 두 개 이상의 IP를 할당 받아서 사용하는 경우(이를 가리켜 Multi-homed 컴퓨터라 하며, 일반적으로 라우터가 이에 해당한다),   
할당 받은 IP중 어떤 주소를 통해서 데이터가 들어오더라도 PORT 번호만 일치하면 수신할 수 있게 된다.   
따라서, 서버 프로그램의 구현에 많이 선호되는 방법이다.   

### 서버 소켓 생성시 IP 주소가 필요한 이유   

서버 소켓은 생성시 자신이 속한 컴퓨터의 IP 주소로 초기화가 이뤄져야 한다.   
즉, 초기화할 IP 주소가 뻔하다.   
그럼에도 IP 주소의 초기화를 요구하는 것에 의문을 가질 수 있다.   
하지만 바로 위에서 언급한, 하나의 컴퓨터에 둘 이상의 IP 주소가 할당될 수 있다는 사실을 통해서 이 부분을 이해할 수 있다.   
   
IP 주소는 컴퓨터에 장착되어 있는 NIC(랜카드)의 개수만큼 부여가 가능하다.   
그리고 이러한 경우에는 서버 소켓이라 할지라도 어느 IP 주소로 들어오는(어느 NIC로 들어오는) 데이터를 수신할지 결정해야 한다.   
때문에, 서버 소켓의 초기화 과정에서 IP 주소 정보를 요구하는 것이다.   
반면, NIC가 하나뿐인 컴퓨터라면 주저 없이 INADDR_ANY를 이용해서 초기화하는 것이 편리하다.   
   
   
   #
# TCP와 UDP에 대한 이해   

### TCP / IP 프로토콜 스택   

다음은 `TCP / IP 프로토콜 스택(Stack, 계층)을 보여준다.   
   
![TCP IP 프로토콜 스택](https://user-images.githubusercontent.com/46395776/97809140-8bc89e00-1cae-11eb-8260-3dddca437b3c.png)   
   
위 그림을 통해서 TCP / IP 스택이 총 네 개의 계층으로 나뉨을 알 수 있는데,   
이는 데이터 송수신의 과정을 네 개의 영역으로 계층화했다는 의미로 받아들일 수 있다.   
즉 `인터넷 기반의 효율적인 데이터 전송`이라는 커다란 하나의 문제를 하나의 덩치 큰 프로토콜 설계로 해결한 것이 아니라,   
그 문제를 작게 나눠서 계층화하려는 노력이 시도되었고,   
그 결과로 탄생한 것이 `TCP / IP 프로토콜 스택`인 것이다.   
   
참고로 좀 더 작게는 OSI 7 계층으로 세분화된다.   
하지만 위의 그림과 같이 4계층으로 구분 짓기도 한다.   
프로그래머의 관점에서는 4계층으로 이해하고 있어도 충분하다.   
   
따라서 우리가 TCP 소켓을 생성해서 데이터를 송수신할 경우에는 다음 네 계층의 도움을 받아 데이터를 송수신하게 된다.   
   
`Application Layer <=> TCP Layer <=> IP Layer <=> Link Layer`   
   
반면에 UDP 소켓을 생성해서 데이터를 송수신할 경우에는 다음 네 계층의 도움을 통해서 데이터를 송수신하게 된다.   
   
`Application Layer <=> UDP Layer <=> IP Layer <=> Link Layer`   
   
그리고 각각의 계층을 담당하는 것은 운영체제와 같은 소프트웨어이기도 하고,   
NIC와 같은 물리적인 장치이기도 하다.   

### TCP / IP 프로토콜의 탄생 배경   

`인터넷을 통한 효율적인 데이터의 송수신`이라는 과제의 해결을 위해서 많은 전문가들이 모여있다.   
이들은 하드웨어 전문가부터 시작해서 시스템 전문가, 라우팅 알고리즘 전문가 등 아주 다양한 분야의 최고 전문가들이다.   
그렇다면 왜 이렇게 많은 분야의 전문가들이 필요한 것일까?   
   
지금까지 우리는 소켓의 생성 및 활용에만 관심을 둬서 생각하지 못했지만, 네트워크는 소프트웨어만 가지고 해결할 수 있는 문제가 아니다.   
소프트웨어가 존재하기 전에 하드웨어적으로 시스템이 구축되어 있어야 하고,   
그러한 물리적 환경을 기반으로 각종 소프트웨어적인 알고리즘을 필요로 한다.   
   
즉, `인터넷을 통한 효율적인 데이터의 송수신`이라는 이슈의 해결을 위해서는 아주 많은 분야의 전문가가 필요하며,   
이들간의 상호 논의로 만들어진 다양한 약속이 또한 필요하다.   
따라서 이 문제는 작은 문제로 나눠서 해결하는 것이 효율적이다.   
   
결국엔 문제를 영역별로 나눠서 `인터넷을 통한 효율적인 데이터의 송수신`에 대한 결론을 얻게 되었다.   
문제를 영역별로 나눠서 해결하다 보니 프로토콜이 여러 개 만들어졌으며,   
이들은 계층구조를 통해서 상호간에 관계를 맺게 되었다.   

### 개방형 시스템(Open System)   

구체적으로 프로토콜을 계층화해서 얻게 되는 장점에는 어떤 것들이 있을까?   
프로토콜 설계의 용이성? 물론 이것도 장점이라 말하기엔 충분하다.   
그러나 이보다 더 중요한 이유가 있으니, 이는 바로 표준화 작업을 통한 `개방형 시스템(Open System)`의 설계이다.   
   
표준이라는 것은 감추는 것이 아니라 활짝 열고 널리 알려서 많은 사람이 따르도록 유도하는 것이다.   
따라서 여러 개의 표준을 근거로 설계된 시스템을 가리켜 `개방형 시스템`이라 하며, 현재 다루고 있는 `TCP / IP 프로토콜 스택` 역시 개방형 시스템의 하나이다.   
   
그렇다면 개방형 시스템의 장점이 무엇인지 살펴보자.   
IP 계층을 담당하는 라우터라는 장비가 있다.   
회사에서 A사의 라우터 장비를 사용하고 있었는데, 이를 B사의 라우터 장비로 교체하려고 한다.   
교체가 가능할까? 물론 어렵지 않게 교체가 가능하다.   
반드시 같은 회사의 같은 모델로 교체해야 하는 것은 아니다.   
왜냐하면 모든 라우터 제조사들이 `IP 계층`의 표준에 맞춰서 라우터를 제작하기 때문이다.   
   
한 가지 예시를 더 살펴보자.   
현재 우리의 컴퓨터에 네트워크 카드, 소위 말하는 랜카드가 달려있는지 확인하자.   
만일 달려있지 않다면 우리는 어렵지 않게 랜카드를 선택할 수 있다.   
모든 랜카드 제조사가 `LINK 계층`의 표준을 따르기 때문이다.   
이것이 바로 개방형 시스템의 장점이다.   
   
이렇듯 표준이 존재한다는 것은 그만큼 빠른 속도의 기술발전이 가능하다는 것을 의미한다.   
그리고 이것이 시스템을 개방형으로 설계하는 가장 큰 이유이기도 하다.   
사실 소프트웨어 공학에서의 `객체지향(Object Oriented)`의 탄생배경에도 소프트웨어의 발전을 위해서는 표준이 필요하다는 생각이 큰 몫을 차지했다.   
그만큼 표준이라는 것은 기술의 발전에 있어서 중요한 요소이다.   

### LINK 계층   

LINK 계층은 물리적인 영역의 표준화에 대한 결과이다.   
이는 가장 기본이 되는 영역으로 LAN, WAN, MAN과 같은 네트워크 표준과 관련된 프로토콜을 정의하는 영역이다.   
두 호스트가 인터넷을 통해 데이터를 주고받으려면 물리적인 연결이 존재해야 하는 것은 당연하다.   
바로 이 부분에 대한 표준을 LINK 계층에서 담당하고 있다.   

### IP 계층   

이제 LINK 계층에 의한 물리적인 연결이 형성되었으니, 데이터를 보낼 기본 준비가 되었다고 할 수 있다.   
그런데 복잡하게 연결되어 있는 인터넷을 통한 데이터의 전송을 위해 선행되어야 할 일은 경로의 선택이다.   
`목적지로 데이터를 전성하기 위해서 중간에 어떤 경로를 거쳐갈 것인가`에 대한 문제를 해결하는 것이 IP 계층이고, 이 계층에서 사용하는 프로토콜이 `IP(Internet Protocol)`이다.   
   
![네트워크 라우팅](https://user-images.githubusercontent.com/46395776/98361903-b3818280-206f-11eb-959c-305fc5b57e66.png)   
   
IP 자체는 `비 연결지향적`이며, `신뢰할 수 없는` 프로토콜이다.   
데이터를 전송할 때마다 거쳐야 할 경로를 선택해 주지만, 그 경로는 일정치 않다.   
특히 데이터 전송 도중에 경로상에 문제가 발생하면 다른 경로를 선택해 주는데, 이 과정에서 데이터가 손실되거나 오류가 발생하는 등의 문제가 발생한다고 해서 이를 해결해주지 않는다.   
즉, 오류발생에 대한 대비가 되어있지 않은 프로토콜이 IP이다.   

### TCP / UDP 게층   

데이터의 전송을 위한 경로의 검색을 IP계층에서 해결해주니, 그 경로를 기준으로 데이터를 전송만하면 된다.   
TCP와 UDP 계층은 이렇듯 IP 계층에서 알려준 경로 정보를 바탕으로 데이터의 실제 송수신을 담당한다.   
때문에, 이 계층을 가리켜 `전송(Transport) 계층`이라 한다.   
   
전송 계층에 존재하는 UDP는 TCP에 비해 상대적으로 간단하며, 이후에 별도로 언급하니 일단은 TCP에 대해서만 추가로 설명한다.   
TCP는 `신뢰성 있는` 데이터의 전송을 담당한다.   
그런데 TCP가 데이터를 보낼 때 기반이 되는 프로토콜이 IP이다.   
이것이 프로토콜이 스택의 구조로 계층화되어 있는 이유이다.   
그러면 이 둘의 관계를 어떻게 이해하면 좋을까?   
   
IP는 오로지 하나의 데이터 패킷(데이터 전송의 기본단위)이 전송되는 과정에만 중심을 두고 설계되었다.   
따라서 여러 개의 데이터 패킷을 전송한다 하더라도 각각의 패킷이 전송되는 과정은 IP에 의해서 진행되므로 전송의 순서는 물론이거니와 전송 그 자체를 신뢰할 수 없다.   
만약에 IP만을 이용해 데이터를 전송한다면 먼저 전송한 A 패킷보다 뒤에 전송한 B 패킷이 먼저 도달할 수도 있다.   
그리고 이어서 전송한 A, B, C 패킷 중에서 A와 C 패킷만 전송될 수 있으며, 그나마 C 패킷은 손상된 상태로 전송될 수도 있다.   
반면에 TCP 프로토콜이 추가되어 데이터를 송수신하면 다음과 같은 대화를 주고받게 된다.   
   
- 호스트 A : 두 번째 패킷까지 잘 받았소!
- 호스트 B : 네 알겠습니다.   
   
- 호스트 A : 세 번째 패킷까지는 잘 받았소!
- 호스트 B : 네 번째 패킷까지 보냈는데요? 네 번째 패킷은 못 받았나 보군요! 그러면 재전송 하겠습니다.   
   
이것이 바로 TCP의 역할이다.   
이렇듯 데이터를 주고받는 과정에서 서로 데이터의 주고 받음을 확인한다면, 그리고 분실된 데이터에 대해서 재전송해준다면, 데이터의 전송을 신뢰할 수 있다.   
비록 IP가 데이터의 전송을 보장하지 않더라도 말이다.   
   
결론적으로 IP의 상위 계층에서 호스트 대 호스트의 데이터 송수신 방식을 약속하는 것이 TCP 그리고 UDP이며,   
TCP는 확인절차를 걸쳐서 신뢰성 없는 IP에 신뢰성을 부여한 프로토콜이라 할 수 있다.   

### APPLICATION 계층   

지금까지 설명한 각 계층의 역할들은 소켓을 생성하면 데이터 송수신과정에서 자동으로 처리되는 것들이다.   
데이터의 전송 경로를 확인하는 과정이라든가 데이터 수신에 대한 응답의 과정이 소켓이라는 것 하나에 감춰져 있기 때문이다.   
그러나 감춰져 있다는 표현보다는 이러한 일들에 대해서 프로그래머를 자유롭게 해줬다는 표현이 더 정확하다.   
즉, 프로그래밍에 있어서 이러한 과정을 일일이 신경 쓰지 않아도 된다는 뜻이다.   
하지만 신경을 쓰지 않아도 될 뿐이지, 몰라도 된다는 뜻은 아니다.   
이러한 이론적인 내용들도 알고 있어야 필요에 맞는 네트워크 프로그램을 작성할 수 있다.   
   
최종적으로 소켓이라는 도구가 우리에게 주어졌고, 우리는 이 도구를 이용해서 무엇인가를 만들면 된다.   
이렇게 무엇인가를 만드는 과정에서 프로그램의 성격에 따라 클라이언트와 서버간의 데이터 송수신에 대한 약속(규칙)들이 정해지기 마련인데, 이를 가리켜 `APPLICATION 프로토콜`이라 한다.   
그리고 대부분의 네트워크 프로그래밍은 APPLICATION 프로토콜의 설계 및 구현이 상당 부분을 차지한다.   
   
   
   #
# TCP 기반 서버, 클라이언트 구현   

### TCP 서버에서의 기본적인 함수 호출 순서   

아래 그림은 TCP 서버 구현을 위한 기본적인 함수의 호출 순서를 보이고 있다.   
대부분의 TCP 서버 프로그램은 이 순서로 구현이 된다.   
   
![tcp 서버의 함수호출 순서](https://user-images.githubusercontent.com/46395776/98365305-8cc64a80-2075-11eb-8def-cda80297fe93.png)   
   
제일 먼저 `socket 함수`의 호출을 통해서 소켓을 생성한다.   
그리고 주소 정보를 담기 위한 구조체 변수를 선언 및 초기화해서 `bind 함수`를 호출하여 소켓에 주소를 할당한다.   
이 두 단계는 이미 위에서 설명한 내용이니, 그 이후의 과정에 대해 다룬다.   

### 연결요청 대기상태로의 진입   

bind 함수 호출을 통해서 소켓에 주소까지 할당했다면, 이번에는 listen 함수 호출을 통해서 `연결요청 대기상태`로 들어갈 차례이다.   
그리고 listen 함수가 호출되어야 클라이언트가 연결요청을 할 수 있는 상태가 된다.   
즉, listen 함수가 호출되어야 클라이언트는 연결요청을 위해서 `connect 함수`를 호출할 수 있다.
만일 listen 함수 호출 이전에 connect 함수를 호출하면 오류가 발생한다.   
   
`int listen(int sock, int backlog);`   

- sock : 연결요청 대기상태에 두고자 하는 소켓의 파일 디스크립터 전달. 이 함수의 인자로 전달된 디스크립터의 소켓이 서버 소켓(리스닝 소켓)이 된다.   
- backlog : 연결요청 대기 큐(Queue)의 크기정보 전달. 5가 전달되면 큐의 크기가 5가 되어 클라이언트의 연결요청을 5개까지 대기시킬 수 있다.   
- 성공 시 파일 디스크립터, 실패 시 -1 반환   
   
여기서 잠시 `연결요청 대기상태`의 의미와 `연결요청 대기 큐`라는 것에 대해서 별도의 설명을 추가하겠다.   
서버가 `연결요청 대기상태`에 있다는 것은 클라이언트가 연결요청을 했을 때, 연결이 수락될 때까지 연결요청 자체를 대기시킬 수 있는 상태에 있다는 것을 의미한다.   
이를 그림을 통해서 설명하겠다.   
   
![연결요청 대기상태](https://user-images.githubusercontent.com/46395776/98369289-11b46280-207c-11eb-96df-8d09b968d130.png)   
   
위 그림을 보면, listen 함수의 첫 번째 인자로 전달된 파일 디스크립터의 소켓이 어떤 용도로 사용되는지 알 수 있다.   
클라이언트의 연결요청도 인터넷을 통해서 흘러 들어오는 일종의 데이터 전송이기 때문에, 이것을 받아들이려면 당연히 소켓이 하나 있어야 한다.   
서버 소켓의 역할이 바로 이것이다.   
즉, 연결 요청을 맞이하는, 일종의 문지기 또는 문의 역할을 한다고 볼 수 있다.   
   
listen 함수가 호출되면, 이렇듯 문지기의 역할을 하는 서버 소켓이 만들어지고, listen 함수의 두 번째 인자로 전달되는 정수의 크기에 해당하는 대기실이 만들어진다.   
이 대기실을 가리켜 `연결요청 대기 큐`라 하며, 서버 소켓과 연결요청 대기 큐가 완전히 준비되어서 클라이언트의 연결요청을 받아들일 수 있는 상태를 가리켜 `연결요청 대기상태`라 한다.   

### 클라이언트의 연결요청 수락   

listen 함수 호출 이후에 클라이언트의 연결요청이 들어왔다면, 들어온 순서대로 연결요청을 수락해야 한다.   
연결요청을 수락한다는 것은 클라이언트와 데이터를 주고받을 수 있는 상태가 됨을 의미한다.   
   
따라서 이러한 상태가 되기 위해 무엇이 필요한지 짐작할 수 있을 것이다. 당연히 소켓이 필요하다!   
전혀 이상할 것이 없다. 데이터를 주고받으려면 소켓이 있어야 한다.   
물론, 위의 내용으로 서버 소켓(리스닝 소켓)을 사용하면 된다고 생각할 수 있다.   
그런데 서버 소켓은 단순히 클라이언트 요청에 대한 문지기 역할을 한다.   
클라이언트와의 데이터 송수신을 위해 이것을 사용하면 문은 누가 지키겠는가?   
때문에, 소켓을 하나 더 만들어야 한다.   
하지만 우리가 소켓을 직접 만들 필요는 없다.   
다음 함수의 호출결과로 소켓이 만들어지고, 이 소켓은 연결요청을 한 클라이언트 소켓과 자동으로 연결되니 말이다.   
   
`int accept(int sock, struct sockaddr* addr, socklen_t* addrlen);`   

- sock : 서버 소켓의 파일 디스크립터 전달.   
- addr : 연결요청 한 클라이언트의 주소정보를 담을 변수의 주소 값 전달. 함수호출이 완료되면 인자로 전달된 주소의 변수에는 클라이언트의 주소 정보가 채워진다.   
- addrlen : 두 번째 매개변수 addr에 전달된 주소의 변수 크기를 바이트 단위로 전달. 단, 크기 정보를 변수에 저장한 다음에 변수의 주소 값을 전달한다. 그리고 함수 호출이 완료되면 크기정보로 채워져 있던 변수에는 클라이언트의 주소 정보 길이가 바이트 단위로 계산되어 채워진다.   
   
accept 함수는 `연결요청 대기 큐`에서 대기중인 클라이언트의 연결요청을 수락하는 기능의 함수이다.   
따라서 accept 함수는 호출 성공 시 내부적으로 `데이터 입출력`에 사용할 소켓을 생성하고, 그 소켓의 파일 디스크립터를 반환한다.   
중요한 점은 소켓이 자동으로 생성되어, 연결요청을 한 클라이언트 소켓에 연결까지 이뤄진다는 점이다.   
아래 그림은 accept 함수 호출 시 일어나는 상황을 보이고 있다.   
   
![연결요청 수락상태](https://user-images.githubusercontent.com/46395776/98370831-8be5e680-207e-11eb-8e76-940171809e1c.jpeg)   
   
위 그림에서는 대기 큐(Queue)에 존재하던 연결요청 하나를 꺼내서 새로운 소켓을 생성한 후에 연결요청을 완료함을 보이고 있다.   
이렇듯 서버에서 별도로 생성한 소켓과 클라이언트 소켓이 직접 연결되었으니, 이제는 데이터를 주고받는 일만 남았다.   

### TCP 클라이언트의 기본적인 함수 호출 순서   

이번에는 클라이언트의 구현 순서에 대해서 이야기하자.   
클라이언트의 구현 과정은 서버에 비해 매우 단순하다.   
`소켓의 생성`, 그리고 `연결의 요청`이 전부이기 때문이다.   
   
![tcp 클라이언트 함수호출 순서](https://user-images.githubusercontent.com/46395776/98371407-7a510e80-207f-11eb-8b7c-9e8ba3055aab.png)   
   
서버의 구현 과정과 비교해서 차이가 있는 부분은 `연결요청`이라는 과정이다.   
이는 클라이언트 소켓을 생성한 후에 서버로 연결을 요청하는 과정이다.   
서버는 listen 함수를 호출한 이후부터 연결요청 대기 큐를 만들어 놓는다.   
따라서 그 이후부터 클라이언트는 연결요청을 할 수 있다.   
그렇다면 클라이언트는 어떻게 연결요청을 할까?   
다음 함수 호출을 통해서 연결요청을 한다.   
   
`int connect(int sock, const struct sockaddr* servaddr, socklen_t addrlen);`   

- sock : 클라이언트 소켓의 파일 디스크립터 전달.   
- servaddr : `연결요청 할 서버의 주소정보`를 담은 변수의 주소 값 전달   
- addrlen : 두 번째 매개변수 servaddr에 전달된 주소의 변수 크기를 바이트 단위로 전달   
   
클라이언트에 의해서 connect 함수가 호출되면 다음 둘 중 한 가지 상황이 되어야 함수가 반환된다(함수 호출이 완료된다).   
   
- 서버에 의해 연결요청이 접수되었다.
- 네트워크 단절 등 오류 상황이 발생해서 연결요청이 중단되었다.   
   
여기서 주의할 사실은 위에서 말하는 `연결요청의 접수`는 서버의 accept 함수 호출을 의미하는 것이 아니라는 점이다.   
이는 클라이언트의 연결요청 정보가 서버의 연결요청 대기 큐에 등록된 상황을 의미하는 것이다.   
때문에 connect 함수가 반환했더라도 당장에 서비스가 이뤄지지 않을 수도 있음을 기억해야 한다.   

### 클라이언트 소켓의 주소 정보는 어디에?   

서버를 구현하면서 반드시 거쳤던 과정 중 하나가 서버 소켓에 IP와 PORT를 할당하는 것이었다.   
그런데 생각해보면 클라이언트 프로그램의 구현 순서에는 소켓의 주소 할당 과정이 없었다.   
그저 소켓을 생성하고 서버로의 연결을 위해서 connect 함수를 호출한 것이 전부였다.   
그렇다면 클라이언트 소켓은 IP와 PORT의 할당이 불필요한 것일까? 물론 아니다!   
네트워크를 통해서 데이터를 송수신하려면 IP와 PORT가 반드시 할당되어야 한다.   
그렇다면 클라이언트 소켓은 언제, 어디서, 어떻게 할당이 가능했던 것일까?   
   
- 언제? : connect 함수가 호출될 때
- 어디서? : 운영체제에서. 보다 정확히 표현하면 `커널`에서
- 어떻게? : IP는 컴퓨터(호스트)에 할당된 IP로, PORT는 임의로 선택해서!   
   
즉, bind 함수를 통해서 소켓에 IP와 PORT를 직접 할당하지 않아도 connect 함수 호출 시 자동으로 소켓에 IP와 PORT가 할당된다.   
따라서 클라이언트 프로그램을 구현할 때에는 bind 함수를 명시적으로 호출할 필요가 없다.   

### TCP 기반 서버, 클라이언트의 함수 호출 관계   

지금까지 TCP 서버, TCP 클라이언트 프로그램의 구현 순서를 설명했는데, 사실 이 둘은 서로 독립된 과정이 아니기 때문에 하나의 과정으로 머리 속에 그릴 수 있어야 한다.   
그래서 이 두 과정을 하나의 그림으로 정리하면 다음과 같다.   
   
![tcp 기반 서버 클라이언트의 함수호출 관계](https://user-images.githubusercontent.com/46395776/98381386-25b49000-208d-11eb-9362-42245e745303.png)   
   
전체적인 흐름을 정리하면, 서버는 소켓 생성 이후에 bind, listen 함수의 연이은 호출을 통해 대기상태에 들어가고, 클라이언트는 connect 함수 호출을 통해서 연결요청을 하게 된다.   
특히 클라이언트는 서버 소켓의 listen 함수 호출 이후에 connect 함수 호출이 가능하다는 사실을 기억할 필요가 있다.   
뿐만 아니라 클라이언트가 connect 함수를 호출하기에 앞서 서버가 accept 함수를 먼저 호출할 수 있다는 사실도 함께 기억해야 한다.   
물론 이때는 클라이언트가 connect 함수를 호출할 때까지 서버는 accept 함수가 호출된 위치에서 블로킹 상태에 놓이게 된다.   
   
   
   #
# Iterative 기반의 서버, 클라이언트 구현   

### Iterative 서버의 구현   

기존에 다뤘던 `hello_server.c` 서버는 한 클라이언트의 요청에만 응답을 하고 바로 종료되어버렸다.   
때문에 연결요청 대기 큐의 크기도 사실상 의미가 없었다.   
그런데 이는 우리가 생각해 오던 서버의 모습이 아니다.   
큐의 크기까지 설정해 놓았다면, 연결요청을 하는 모든 클라이언트에게 약속되어 있는 서비스를 제공해야 한다.   
그렇다면 계속해서 들어오는 클라이언트의 연결요청을 수락하기 위해서는 서버의 코드 구현을 어떤 식으로 확장해야 할까?   
단순히 생각하자! 반복문을 삽입해서 accept 함수를 반복 호출하면 된다.   
   
![iterative 서버의 함수호출 순서](https://user-images.githubusercontent.com/46395776/98382702-dd966d00-208e-11eb-81c9-ec80aafe84c7.png)   
   
위 그림의 흐름도를 보충설명 한다면, accept 함수가 호출된 다음에 입력된 함수인 read, write 함수를 호출하고 있다.   
그리고 이어서 close 함수를 호출하고 있는데, 이는 서버 소켓을 대상으로 하는 것이 아니라, accept 함수의 호출과정에서 생성된 소켓을 대상으로 하는 것이다.   
close 함수까지 호출되었다면 한 클라이언트에 대한 서비스가 완료된 것이다.   
그럼 이어서 또 다른 클라이언트에게 서비스하기 위해서 무엇을 해야겠는가?   
또 다시 accept 함수부터 호출해야 한다.   
   
위의 모델은 한 순간에 하나의 클라이언트에게만 서비스를 제공할 수 있는 모델이다.   
이후에 `프로세스`와 `쓰레드`를 다루게 되면, 동시에 둘 이상의 클라이언트에게 서비스를 제공하는 서버를 만들 수 있게 된다.   

### Iterative 에코 서버, 에코 클라이언트   

앞서 설명한 형태의 서버를 가리켜 `Iterative 서버`라 한다.   
그리고 서버가 Iterative 형태로 동작한다 해도 클라이언트 코드에는 차이가 없음을 이해할 수 있다.   
그러면 이번에는 Iterative 형태로 동작하는 에코 서버, 그리고 이와 함께 동작하는 에코 클라이언트를 작성해 본다.   
먼저 프로그램의 기본 동작 방식을 정리하면 다음과 같다.   
   
- 서버는 한 순간에 하나의 클라이언트와 연결되어 에코 서비스를 제공한다.
- 서버는 총 다섯 개의 클라이언트에게 순차적으로 서비스를 제공하고 종료한다.
- 클라이언트는 프로그램 사용자로부터 문자열 데이터를 입력 받아서 서버에 전송한다.
- 서버는 전송 받은 문자열 데이터를 클라이언트에게 재전송한다. 즉, 에코 시킨다.
- 서버와 클라이언트 간의 문자열 에코는 클라이언트가 Q 또는 q를 입력할 때까지 계속한다.   
   
위의 요구사항에 맞춰 `echo_server.c`와 `tcp-ip-socket-client 저장소`의 `echo_client.c`를 작성하였으니 코드 참고 바란다.   

### 에코 클라이언트의 문제점   

다음은 `tcp-ip-socket-client 저장소`의 `echo_client.c` 코드 중 입출력 문장이다.   
   
<pre>
<code>

send(hSocket, message, strlen(message), 0);
strLen = recv(hSocket, message, BUF_SIZE - 1, 0);
message[strLen] = 0;
printf("Message from server: %s", message);

</code>
</pre>   
   
위의 코드는 다음과 같은 잘못된 가정이 존재한다.   
   
- read(window에선 위의 recv), write(window에선 위의 send) 함수가 호출될 때마다 문자열 단위로 실제 입출력이 이뤄진다.   
   
물론 write 함수를 호출할 때마다 하나의 문장을 전송하니, 이렇게 가정하는 것도 무리는 아니다.   
하지만 TCP는 데이터의 경계가 존재하지 않는 특성이 있다는 것을 기억하는가?   
여기서 구현한 클라이언트는 TCP 클라이언트이기 때문에 둘 이상의 write 함수 호출로 전달된 문자열 정보가 묶여서 한 번에 서버로 전송될 수 있다.   
그리고 그러한 상황이 발생하면 클라이언트는 한 번에 둘 이상의 문자열 정보를 서버로부터 되돌려 받아서, 원하는 결과를 얻지 못할 수 있다.   
그리고 서버가 다음과 같이 판단하는 상황도 생각해봐야 한다.   
   
- 문자열의 길이가 제법 긴 편이니, 문자열을 두 개의 패킷에 나눠서 보내야겠군!   
   
서버는 한 번의 write 함수 호출로 데이터 전송을 명령했지만, 전송할 데이터의 크기가 크다면, 운영체제는 내부적으로 이를 여러 개의 조각으로 나눠서 클라이언트에게 전송할 수도 있는 일이다.   
그리고 이 과정에서 데이터의 모든 조각이 클라이언트에게 전송되지 않았음에도 불구하고, 클라이언트는 read 함수를 호출할지도 모른다.   
이 모든 문제가 TCP의 데이터 전송 특성에서 비롯된 것이다.   
   
물론 우리가 구현헌 에코 서버와 에코 클라이언트는 별 무리 없이 제대로 된 서비스 결과를 보이고 있다.   
그러나 이는 단순히 운이 좋았던 것이다! 송수신하는 데이터의 크기가 작고, 실제 실행환경이 하나의 컴퓨터 또는 근거리에 놓여있는 두 개의 컴퓨터이다 보니 오류가 발생하지 않는 것일 뿐, 오류의 발생 확률은 여전히 존재한다.   
   
   
   #
# 에코 클라이언트의 완벽 구현!   

### 에코 서버는 문제가 없고, 에코 클라이언트만 문제가 있을까?   

문제는 에코 서버에 있지 않고, 에코 클라이언트에 있다.   
그런데 코드만 놓고 비교하면, 이 부분이 이해되지 않을 수 있다.   
입출력에 사용된 함수의 호출문이 동일하기 때문이다.   
먼저 에코 서버의 입출력 문장을 다시 보자.   
   
<pre>
<code>

while ((strLen = recv(hClntSock, message, BUF_SIZE, 0)) != 0)
	send(hClntSock, message, strLen, 0);

</code>
</pre>   
   
이어서 에코 클라이언트의 입출력 문장을 다시 보자.   
   
<pre>
<code>

send(hSocket, message, strlen(message), 0);
strLen = recv(hSocket, message, BUF_SIZE - 1, 0);

</code>
</pre>   
   
둘 다 recv 함수와 send 함수를 반복 호출하는데 차이가 없다.   
실제로 앞서 보인 에코 클라이언트는 자신이 서버로 전송한 데이터를 100% 수신한다.   
다만 수신하는 단위에 문제가 있을 뿐이다.   
클라이언트 코드를 조금 더 살펴보자.   
   
<pre>
<code>

while (1) {
	fputs("Input message(Q to quit): ", stdout);
	fgets(message, BUF_SIZE, stdin);

	if (!strcmp(message, "q\n") || !strcmp(message, "Q\n"))
		break;

	send(hSocket, message, strlen(message), 0);
	strLen = recv(hSocket, message, BUF_SIZE - 1, 0);
	message[strLen] = 0;
	printf("Message from server: %s", message);
}

</code>
</pre>   
   
이제 이해가 되겠는가?   
에코 클라이언트는 문자열을 전송한다.   
그것도 send 함수 호출을 통해서 한방에 전송한다.   
그리고 recv 함수 호출을 통해서 자신이 전송한 문자열 데이터를 한방에 수신하기를 원하고 있다. 바로 이것이 문제이다!   
   
결국엔 서버로부터 에코 클라이언트에게 문자열 데이터가 전부 전송되니까 기다리면 될 수 있다.   
시간이 좀 지나서 recv 함수를 호출하면 한방에 문자열 데이터를 수신할 수는 있다.   
하지만 얼마나 기다려야 되겠는가? 얼마나 기다려야 서버로 보냈던 문자열이 모두 자신에게 전송되어 있는지 알 수 없다.   
이치에 맞는 클라이언트라면, 문자열 데이터가 전송되었을 때, 이를 모두 읽어서 출력해야 한다.   

### 에코 클라이언트의 해결책   

위의 문제는 해결이 쉽다.   
클라이언트가 수신해야 할 데이터의 크기를 미리 알고 있기 때문이다.   
예를 들어서 크기가 20바이트인 문자열을 전송했다면, 20바이트를 수신할 때까지 반복해서 read(위의 윈도우에서는 recv) 함수를 호출하면 된다.   
`tcp-ip-socket-client 저장소`의 `echo_client2.c`를 참고하면 된다.   
   
   
   #
# TCP의 이론적인 이야기   

### TCP 소켓에 존재하는 입출력 버퍼   

TCP 소켓의 데이터 송수신에는 경계가 없다는 특성이 있다.   
따라서 서버가 한 번의 write 함수 호출을 통해서 40바이트를 전송해도 클라이언트는 네 번의 read 함수 호출을 통해서 10바이트씩 데이터를 수신하는 것이 가능하다.   
그런데 이러한 현상에 의문이 생긴다.   
서버는 데이터를 한 번에 40바이트를 전송했는데, 클라이언트가 이를 여유 있게 조금씩 수신하니 말이다.   
클라이언트가 10바이트만 먼저 수신했다면, 서버가 보낸 나머지 30바이트는 어디서 대기하고 있는 것일까?   
   
사실 write 함수가 호출되는 순간이 데이터가 전송되는 순간이 아니고, read 함수가 호출되는 순간이 데이터가 수신되는 순간이 아니다.   
정확히 말하면 write 함수가 호출되는 순간 데이터는 `출력버퍼`로 이동을 하고, read 함수가 호출되는 순간 `입력버퍼`에 저장된 데이터를 읽어 들이게 된다.   
   
![tcp 소켓의 입출력 버퍼](https://user-images.githubusercontent.com/46395776/98434658-14af6180-2115-11eb-82a3-249de5cb2a69.png)   
   
위 그림이 보이듯이 write 함수가 호출되면 출력버퍼라는 곳에 데이터가 전달되어서 상황에 맞게 적절히(한 번에 보내든 나눠서 보내든) 데이터를 상대방의 입력버퍼로 전송한다.   
그러면 상대방은 read 함수 호출을 통해서 입력버퍼에 저장된 데이터를 읽게 되는 것이다.   
이러한 입출력 버퍼의 특성 몇 가지를 정리하면 다음과 같다.   
   
- 입출력 버퍼는 TCP 소켓 각각에 대해 별도로 존재한다.
- 입출력 버퍼는 소켓 생성시 자동으로 생성된다.
- 소켓을 닫아도 출력버퍼에 남아있는 데이터는 계속해서 전송이 이뤄진다.
- 소켓을 닫으면 입력버퍼에 남아있는 데이터는 소멸되어버린다.   
   
그렇다면 다음과 같은 상황이 발생하면 어떤 일이 일어날까?   
입출력 버퍼의 존재를 알았으니, 다음과 같은 상황에서의 흐름을 유추해볼 수 있다.   
   
- 클라이언트의 입력버퍼 크기가 50바이트인데, 서버에서 100바이트를 전송하였다.   
   
이는 문제가 아닐 수 없다. 입력버퍼의 크기가 50바이트인데, 100바이트가 전송되니 말이다.   
하지만 입력버퍼의 크기를 초과하는 분량의 데이터 전송은 발생하지 않는다!   
왜냐하면 TCP가 `데이터의 흐름`까지 컨트롤하기 때문이다.   
TCP에는 `슬라이딩 윈도우(Sliding Window)`라는 프로토콜이 존재한다.   
이 프로토콜로 인해 각 소켓의 `입력버퍼`는 여유 공간이 얼마인지 상대 소켓의 `출력버퍼`에 알리며 데이터 전송을 이뤄낸다.   
이렇듯 서로 대화를 주고받으면서 데이터를 송수신하기 때문에, 버퍼가 차고 넘쳐서 데이터가 소멸되는 일이 TCP에서는 발생하지 않는다.   

### TCP의 내부 동작원리1 : 상대 소켓과의 연결   

TCP 소켓의 생성에서 소멸의 과정까지 거치게 되는 일을 크게 나누면, 다음 세 가지로 구분할 수 있다.   
   
- 상대 소켓과의 연결
- 상대 소켓과의 데이터 송수신
- 상대 소켓과의 연결종료   
   
TCP 소켓은 연결설정 과정에서 총 세 번의 대화를 주고 받는다.   
그래서 이를 가리켜 `Three-way handshaking`이라 한다.   
   
![3 way handshaking](https://user-images.githubusercontent.com/46395776/98435559-54774880-2117-11eb-8b4b-abc06fb2a3f0.png)   
   
소켓은 전 이중(Full-duplex) 방식으로 동작하므로 양방향으로 데이터를 주고받을 수 있다.   
따라서 데이터 송수신에 앞서 준비과정이 필요하다.   
먼저 위의 그림에서 연결요청을 하는 Client가 Server에게 다음 메시지를 전달하고 있다.   
   
- [SYN] seq: 100, ack: -   
   
이는 seq가 100, ack는 비어있음을 뜻하는데, 여기서 seq 100이 의미하는 바는 다음과 같다.   
   
- 내가 지금 보내는 이 패킷에 100이라는 번호를 부여하니, 잘 받았다면 다음에는 101번 패킷을 전달하라고 내게 말해달라!   
   
이는 처음 연결요청에 사용되는 메시지이기 때문에 이 메시지를 가리켜 SYN이라 한다.   
그리고 SYN은 Synchronization의 줄임 말로써, 데이터 송수신에 앞서 전송되는 `동기화 메시지`라는 의미를 담고 있다.   
이어서 호스트 B가 호스트 A에게 다음 메시지를 전달하고 있다.   
   
- [SYN + ACK] seq: 200, ack: 101   
   
이는 seq가 200, ack가 101임을 뜻하는데, 여기서 seq 200이 의미하는 바는 다음과 같다.   
   
- 내가 지금 보내는 이 패킷에 200이라는 번호를 부여하니, 잘 받았다면 다음에는 201번 패킷을 전달하라고 내게 말해달라!   
   
그리고 ack 101이 의미하는 바는 다음과 같다.   
   
- 좀 전에 전송한 seq가 100인 패킷은 잘 받았으니, 다음 번에는 seq가 101인 패킷을 전송하기 바란다!   
   
즉, 처음 호스트 A가 전송한 패킷에 대한 `응답 메시지(ack 101)`와 함께 호스트 B의 데이터 전송을 위한 `동기화 메시지(seq 200)`를 함께 묶어서 보내고 있다.   
그래서 이러한 유형의 메시지를 가리켜 `SYN + ACK`라 한다.   
   
이렇듯 데이터의 송수신에 앞서, 송수신에 사용되는 패킷에 번호를 부여하고, 이 번호 정보를 상대방에게 알리는 이유는 데이터의 손실을 막기 위함이다.   
이렇게 패킷에 번호를 부여해서 확인하는 절차를 거치기 때문에 손실된 데이터의 확인 및 재전송이 가능한 것이고, 때문에 TCP는 손실 없는 데이터의 전송을 보장하는 것이다.   
그럼 마지막으로 Client가 Server에게 전송한 메시지를 살펴보자.   
   
- [ACK] seq: 101, ack: 201   
   
이미 앞서 한차례씩 송수신한 패킷에서 보였듯이 TCP의 연결과정에서 패킷을 보낼 때에는 항상 번호를 부여한다.   
그래서 seq 101이 부여되었다.   
앞서 보낸 패킷의 seq가 100이었으니, 이번에는 이보다 1이 증가한 101이 부여된 것이다.   
그리고 이 패킷은 다음의 메시지 전달을 목적으로 전송되었다.   
   
- 좀 전에 전송한 seq가 200인 패킷은 잘 받았으니, 다음 번에는 201인 패킷을 전송하기 바란다!   
   
때문에, ack 201이 추가된 형태의 ack 메시지가 전송되었다.   
이로써 Client(호스트 A), Server(호스트 B) 상호간에 데이터 송수신을 위한 준비가 모두 되었음을 서로 인식하게 되었다.   

### TCP의 내부 동작원리2 : 상대 소켓과의 데이터 송수신   

처음 진행한 Three-way handshaking을 통해서 데이터의 송수신 준비가 끝났으니, 이제 본격적으로 데이터를 송수신할 차례가 되었다.   
데이터 송수신의 기본 방식은 다음과 같다.   
   
![tcp 소켓의 데이터 송수신 과정](https://user-images.githubusercontent.com/46395776/98436523-5b09be00-211f-11eb-8cc4-6cb49c3fa303.png)   
   
위 그림은 호스트 A가 호스트 B에게 총 200바이트를 두 번에 나눠서(두 개의 패킷에 나눠서) 전송하는 과정을 보인 것이다.   
먼저 호스트 A가 100바이트의 데이터를 하나의 패킷에 실어 전송하였는데, 패킷의 SEQ를 1200으로 부여하고 있다.   
때문에 호스트 B는 이를 근거로 패킷이 제대로 수신되었음을 알려야 하기에, ACK 1301 메시지를 담은 패킷을 호스트 A에 전송하고 있다.   
이 때, ack 번호가 1201이 아닌 1301인 이유는 ACK 번호를 전송된 바이트 크기만큼 추가로 증가시켰기 때문이다.   
   
이렇듯 ACK 번호를 전송된 바이트 크기만큼 추가로 증가시키지 않으면, 패킷의 전송은 확인할 수 있을지 몰라도, 패킷에 담긴 100바이트가 전부 전송되었는지, 아니면 그 중 일부가 손실되고 80바이트만 전송되었는지 알 방법이 없다.   
그래서 다음의 공식을 기준으로 ACK 메시지를 전송한다.   
   
- ACK 번호 -> SEQ 번호 + 전송된 바이트 크기 + 1   
   
마지막에 1을 더한 이유는 Three-way handshaking에서도 보였듯이, 다음 번에 전달된 SEQ의 번호를 알리기 위함이다.   
다음은 중간에 패킷이 소멸되는 상황이다.   
   
![tcp 소켓의 데이터 송신 오류](https://user-images.githubusercontent.com/46395776/98436615-1b8fa180-2120-11eb-84e2-ce33e729246b.png)   
   
위 그림은 SEQ 1301인 패킷에 100바이트 데이터를 실어서 호스트 B로 전송되고 있음을 보이고 있다.   
그런데 중간에 문제가 발생해서 호스트 B에 전송되지 못했다.   
이러한 경우 호스트 A는 일정시간이 지나도 SEQ 1301에 대한 ACK 메시지를 받지 못하기 때문에 재전송을 진행한다.   
이렇듯 데이터의 손실에 대한 재전송을 위해서, TCP 소켓은 ACK 응답을 요구하는 패킷 전송 시에 `타이머`를 동작시킨다.   
그리고 해당 타이머가 `Time-out!`되었을 때, 패킷을 재전송한다.   

### TCP의 내부 동작원리3 : 상대 소켓과의 연결종료   

![tcp 소켓의 연결종료 과정](https://user-images.githubusercontent.com/46395776/98436695-ba1c0280-2120-11eb-83db-0f50bd5b75d4.png)   
   
위 그림에서 패킷 안에 삽입되어 있는 FIN은 종료를 알리는 메시지를 뜻한다.   
즉, 상호간에 FIN 메시지를 한 번씩 주고 받고서 연결이 종료되는데, 이 과정이 네 단계에 걸쳐서 진행되기 때문에 이를 가리켜 `Four-way handshaking`이라고 부른다.   
그리고 SEQ와 ACK의 의미는 앞서 설명한 내용과 같다.   
다만 ACK 5001이 호스트 A에 두 번 전달된 것이 낯설 것이다.   
그러나 FIN 메시지에 포함된 ACK 5001은 앞서 전송한 ACK 메시지가 수신된 이후로 데이터 수신이 없었기 때문에 재전송된 것이다.   
   
   
   #
# UDP에 대한 이해   

### UDP 소켓의 특성   

편지를 예로 들면서 UDP의 동작 원리를 설명한다.   
이는 UDP의 설명에 사용되는 전통적인 예로써 완벽히 UDP와 맞아 떨어지는 특징이 있다.   
편지를 보내기 위해서는 일단 편지봉투에다가 보내는 사람과 받는 사람의 주소정보를 써 넣어야 한다.   
그리고 우표를 붙여서 우체통에 넣어주면 끝이다.   
다만 편지의 특성상 보내고 나서 상대방의 수신여부를 확인할 길은 없다.   
물론 전송 도중에 편지가 분실될 확률도 없지 않다.   
즉, 편지는 신뢰할 수 없는 전송 방법이다.   
이와 마찬가지로 UDP 소켓은 신뢰할 수 없는 전송 방법을 제공한다.   
   
이렇듯 `신뢰성`만 놓고 보면 분명 TCP가 UDP보다 좋은 프로토콜이다.   
하지만 UDP는 TCP보다 훨씬 간결한 구조로 설계되어있다.   
ACK와 같은 응답 메시지를 보내는 일도 없으며, SEQ와 같이 패킷에 번호를 부여하는 일도 없다.   
때문에 상황에 따라서 TCP보다 훨씬 좋은 성능을 발휘한다.   
물론 프로그래밍의 관점에서 보더라도 UDP는 TCP보다 구현이 용이하다.   
게다가 UDP도 TCP만큼은 아니지만 생각만큼 데이터의 손실이 자주 발생하는 것은 아니기 때문에, 신뢰성보다 성능이 중요시되는 상황에서는 UDP가 좋은 선택이 될 수 있다.   
   
그렇다면 UDP의 역할은 어디까지일까?   
앞서 TCP는 신뢰성 없는 IP를 기반으로 신뢰성 있는 데이터의 송수신을 위해서 `흐름제어(Flow Control)`를 한다고 설명했는데, 바로 이 흐름제어가 UDP에는 존재하지 않는다.   
즉, 흐름제어가 UDP와 TCP를 구분 지어주는 가장 큰 차이점이다.   

### UDP의 내부 동작원리   

UDP는 TCP와 달리 흐름제어를 하지 않는다.   
UDP의 역할이 어디까지인지 구체적으로 설명한다. 이를 위해 다음 그림을 보자.   
   
![패킷 전송에 있어서의 UDP와 IP 역할](https://user-images.githubusercontent.com/46395776/98437915-9f9a5700-2129-11eb-86e4-321547afe2c1.png)   
   
위 그림에서 보이듯이 호스트 B를 떠난 UDP 패킷이 호스트 A에게 전달되도록 하는 것은 IP의 역할이다.   
그런데 이렇게 전달된 UDP 패킷을 호스트 A 내에 존재하는 UDP 소켓 중 하나에게 최종 전달하는 것은 IP의 역할이 아니다. 바로 UDP의 역할이다.   
즉, UDP의 역할 중 가장 중요한 것은 호스트로 수신된 패킷을 PORT 정보를 참조하여 최종 목적지인 UDP 소켓에 전달하는 것이다.   

### UDP의 효율적 사용   

네트워크 프로그래밍의 대부분이 TCP를 기반으로 구현될 것 같지만, UDP를 기반으로 구현되는 경우도 흔히 볼 수 있다.   
그러면 언제 UDP를 사용하는 것이 효율적인지 생각해보자.   
그런데 이에 앞서 UDP도 나름대로 상당히 신뢰할만하다는 것을 언급한다.   
인터넷의 특성상 손실되는 정보들이 많음에도 불구하고 생각보다는 신뢰할만하다.   
그래도 1만개의 패킷을 보냈는데, 그 중 1개만 손실 되어도 문제가 발생하는 `압축파일`의 경우에는 반드시 TCP를 기반으로 송수신이 이뤄져야 한다.   
왜냐하면 압축파일은 그 특성상 파일의 일부만 손실되어도 압축의 해제가 어렵기 때문이다.   
그러나 인터넷 기반으로 실시간 영상 및 음성을 전송하는 경우에는 얘기가 조금 다르다.   
멀티미디어 데이터는 그 특성상 일부가 손실되어도 크게 문제되지 않는다.   
잠깐의 화면 떨림, 또는 아주 작은 잡음 정도는 그냥 넘어갈만하다.   
하지만 실시간으로 서비스를 해야 하므로 속도가 상당히 중요한 요소가 된다.   
때문에 TCP가 하는 흐름제어의 과정은 귀찮게 느껴지는 것이다.   
이러한 경우가 UDP 기반의 구현을 고려할만한 상황이다.   
그러나 UDP가 TCP에 비해서 언제나 빠른 속도를 내는 것은 아니다.   
TCP가 UDP에 비해 느린 이유 두 가지만 달라고 하면, 다음 두 가지를 들 수 있다.   
   
- 데이터 송수신 이전, 이후에 거치는 연결설정 및 해제과정
- 데이터 송수신 과정에서 거치는 신뢰성보장을 위한 흐름제어   
   
따라서 송수신하는 데이터의 양은 작으면서 잦은 연결이 필요한 경우에는 UDP가 TCP보다 훨씬 효율적이고 빠르게 동작한다.   
   
   
   #
# UDP 기반 서버 / 클라이언트의 구현   

### UDP에서의 서버와 클라이언트는 연결되어 있지 않다.   

UDP 서버, 클라이언트는 TCP와 같이 연결된 상태로 데이터를 송수신하지 않는다.   
때문에 TCP와 달리 연결 설정의 과정이 필요 없다.   
따라서 TCP 서버 구현과정에서 거쳤던 listen 함수와 accept 함수의 호출은 불필요하다.   
UDP 소켓의 생성과 데이터의 송수신 과정만 존재할 뿐이다.   

### UDP에서는 서버건 클라이언트건 하나의 소켓만 있으면 된다.   

TCP는 1대 1의 연결을 필요로 하지만, UDP는 연결의 개념이 존재하지 않는다.   
따라서 UDP는 서버 소켓과 클라이언트 소켓의 구분이 없다.   
TCP는 서버에서 열 개의 클라이언트에게 서비스를 제공하려면 문지기 역할을 하는 서버 소켓을 제외하고도 열 개의 소켓이 더 필요했다.   
그러나 UDP는 연결의 개념이 존재하지 않으므로 하나의 소켓으로 둘 이상의 영역과 데이터 송수신이 가능하다.   

### UDP 기반의 데이터 입출력 함수   

TCP 소켓을 생성하고 나서 데이터를 전송하는 경우에는, 주소 정보를 따로 추가하는 과정이 필요 없다.   
왜냐하면 TCP 소켓은 목적지에 해당하는 소켓과 연결된 상태이기 때문이다.   
즉, TCP 소켓은 목적지의 주소 정보를 이미 알고 있는 상태이다.   
   
그러나 UDP 소켓은 연결 상태를 유지하지 않으므로(UDP 소켓은 단순히 우체통의 역할만 하므로), 데이터를 전송할 때마다 반드시 목적지의 주소 정보를 별도로 추가해야 한다.   
이는 우체통에 넣을 우편물에 주소 정보를 써 넣는 것에 비유할 수 있다.   
다음은 주소 정보를 써 넣으면서 데이터를 전송할 때 호출하는 UDP 관련 함수들이다.   
   
`ssize_t sendto(int sock, void* buff, size_t nbytes, int flags, struct sockaddr* to, socklen_t addrlen);`   

- sock : 데이터 전송에 사용될 UDP 소켓의 파일 디스크립터를 인자로 전달.
- buff : 전송할 데이터를 저장하고 있는 버퍼의 주소 값 전달.
- nbytes : 전송할 데이터 크기를 바이트 단위로 전달.
- flags : 옵션 지정에 사용되는 매개변수. 지정할 옵션이 없다면 0 전달.
- to : 목적지 주소 정보를 담고 있는 sockaddr 구조체 변수의 주소 값 전달.
- addrlen : 매개변수 to로 전달된 주소 값의 구조체 변수 크기 전달.
   
위 함수가 이전에 소개한 TCP 기반의 출력함수와 가장 비교되는 것은 목적지 주소 정보를 요구하고 있다는 점이다.   
그러면 이어서 UDP 데이터 수신에 사용되는 함수를 소개한다.   
UDP 데이터는 발신지가 일정치 않기 때문에 발신지 정보를 얻을 수 있도록 함수가 정의되어 있다.   
즉, 이 함수는 UDP 패킷에 담겨 있는 발신지 정보를 함께 반환한다.   
   
`ssize_t recvfrom(int sock, void* buff, size_t nbytes, int flags, struct sockaddr* from, socklen_t* addrlen);`   

- sock : 데이터 수신에 사용될 UDP 소켓의 파일 디스크립터를 인자로 전달.
- buff : 데이터 수신에 사용될 버퍼의 주소 값 전달.
- nbytes : 수신할 최대 바이트 수 전달. 때문에 매개변수 buff가 가리키는 버퍼의 크기를 넘을 수 없다.
- flags : 옵션 지정에 사용되는 매개변수. 지정할 옵션이 없다면 0 전달.
- from : 발신지 정보를 채워 넣을 sockaddr 구조체 변수의 주소 값 전달.
- addrlen : 매개변수 from으로 전달된 주소에 해당하는 구조체 변수의 크기 정보를 담고 있는 변수의 주소값 전달.   
   
### UDP 클라이언트 소켓의 주소정보 할당   

지금까지 위에서 UDP 기반의 서버, 클라이언트 프로그램 구현에 대해 설명했다.   
그런데, UDP 클라이언트 프로그램을 가만히 보면(tcp-ip-client 저장소의 uecho_client.c 참고!), IP와 PORT를 소켓에 할당하는 부분이 눈에 띄지 않는다.   
TCP 클라이언트의 경우에는 connect 함수 호출 시 자동으로 할당되었는데, UDP 클라이언트의 경우에는 그러한 기능을 대신 할만한 함수 호출문조차 보이지 않는다.   
도대체 어느 시점에 IP와 PORT가 할당되는 것일까?   
   
UDP 프로그램에서는 데이터를 전송하는 sendto 함수호출 이전에 해당 소켓에 주소 정보가 할당되어 있어야 한다.   
따라서 sendto 함수 호출 이전에 bind 함수를 호출해서 주소 정보를 할당해야 한다.   
물론 bind 함수는 TCP 프로그램의 구현에서 호출되었던 함수이다.   
그러나 이 함수는 TCP와 UDP를 가리지 않으므로 UDP 프로그램에서도 호출 가능하다.   
그리고 만약에 sendto 함수 호출 시까지 주소 정보가 할당되지 않았다면, sendto 함수가 처음 호출되는 시점에 해당 소켓에 IP와 PORT 번호가 자동으로 할당된다.   
또한, 이렇게 한 번 할당되면 프로그램이 종료될 때까지 주소 정보가 그대로 유지되기 때문에 다른 UDP 소켓과 데이터를 주고받을 수 있다.   
물론 IP는 호스트의 IP로, PORT는 사용하지 않는 PORT 번호 하나를 임의로 골라서 할당하게 된다.   
   
이렇듯 sendto 함수 호출 시 IP와 PORT 번호가 자동으로 할당되기 때문에 일반적으로 UDP의 클라이언트 프로그램에서는 주소 정보를 할당하는 별도의 과정이 불필요하다.   
그래서 tcp-ip-client 저장소의 uecho_client.c에서도 별도의 주소 정보 할당 과정을 생략했으며, 이것이 일반적인 구현 방법이다.   

### connected UDP 소켓, unconnected UDP 소켓   

TCP 소켓에는 데이터를 전송할 목적지의 IP와 PORT 번호를 등록하는 반면, UDP 소켓에는 데이터를 전송할 목적지의 IP와 PORT 번호를 등록하지 않는다.   
때문에, sendto 함수 호출을 통한 데이터의 전송 과정은 다음과 같이 크게 세 단계로 나눌 수 있다.   
   
- 1단계 : UDP 소켓에 목적지의 IP와 PORT 번호 등록
- 2단계 : 데이터 전송
- 3단계 : UDP 소켓에 등록된 목적지 정보 삭제   
   
즉, sendto 함수가 호출될 때마다 위의 과정을 반복하게 된다.   
이렇듯 목적지의 주소 정보가 계속해서 변경되기 때문에 하나의 UDP 소켓을 이용해서 다양한 목적지로 데이터 전송이 가능한 것이다.   
그리고 이렇게 목적지 정보가 등록되어 있지 않은 소켓을 가리켜 `unconnected 소켓`이라 하고, 반면 목적지 정보가 등록되어 있는 소켓을 가리켜 `connected 소켓`이라 한다.   
물론 UDP 소켓은 기본적으로 unconnected 소켓이다.   
그런데 이러한 UDP 소켓은 다음과 같은 상황에서는 매우 불합리하게 동작한다.   
   
- IP 211.210.147.82, PORT 82번으로 준비된 총 세 개의 데이터를 세 번의 sendto 함수 호출을 통해서 전송한다.   
   
이 경우 위에서 정리한 데이터 전송 세 단계를 총 3회 반복해야 한다.   
그래서 하나의 호스트와 오랜 시간 데이터를 송수신해야 한다면, UDP 소켓을 connected 소켓으로 만드는 것이 효율적이다.   
위의 1단계와 3단계가 UDP 데이터 전송 과정의 약 1/3에 해당한다고 하니, 이 시간을 줄임으로 적지 않은 성능향상을 기대할 수 있다.   

### connected UDP 소켓 생성   

connected UDP 소켓을 생성하는 방법은 의외로 간단하다.   
UDP 소켓을 대상으로 connect 함수만 호출해주면 된다.   
   
<pre>
<code>

sock = socket(PF_INET, SOCK_DRAM, 0);
memset(&adr, 0, sizeof(adr));
adr.sin_family = AF_INET;
adr.sin_addr.s_addr = ....
adr.sin_port = ....
connect(sock, (struct sockaddr*)&adr, sizeof(adr));

</code>
</pre>   
   
위의 코드를 언뜻 보면 TCP 소켓 생성 과정의 일부처럼 보인다.   
하지만 socket 함수의 두 번째 인자가 SOCK_DGRAM이지 않은가?   
이는 분명 UDP 소켓의 생성 과정이다.   
물론 UDP 소켓을 대상으로 connect 함수를 호출했다고 해서 목적지의 UDP 소켓과 연결 설정 과정을 거친다거나 하지는 않는다.   
다만 UDP 소켓에 목적지의 IP와 PORT 정보가 등록될 뿐이다.   
이로써 이후부터는 TCP 소켓과 마찬가지로 sendto 함수가 호출될 때마다 데이터 전송의 과정만 거치게 된다.   
뿐만 아니라 송수신의 대상이 정해졌기 때문에 sendto, recvfrom 함수가 아닌 write, read 함수의 호출로도 데이터를 송수신할 수 있다.   

### UDP 데이터그램(Datagram)   

UDP 소켓이 전송하는 패킷을 가리켜 데이터그램이라고 표현하기도 하는데, 사실 데이터그램도 패킷의 일종이다.   
다만 TCP 패킷과 달리 데이터의 일부가 아닌, 그 자체가 하나의 데이터로 의미를 가질 때 데이터그램이라 표현할 뿐이다.   
이는 UDP의 데이터 전송 특성과 관계가 있다.   
UDP는 데이터의 경계가 존재하기 때문에 하나의 패킷이 하나의 데이터로 간주된다.   
따라서 데이터그램이라고 표현하는 것이다.   
   
   
   #
# TCP 기반의 Half-close   

### 일방적인 연결종료의 문제점   

리눅스의 close 함수 호출과 윈도우의 closesocket 함수 호출은 `완전종료`를 의미한다.   
완전종료라는 것은 데이터를 전송하는 것은 물론이거니와 수신하는 것조차 더 이상 불가능한 상황을 의미한다.   
때문에, 한쪽에서의 일방적인 close 또는 closesocket 함수 호출은 경우에 따라서 우아해 보이지 못할 수 있다.   
   
![일방적 연결종료](https://user-images.githubusercontent.com/46395776/98442875-fbc1a300-214a-11eb-9ac3-3a8f96c76de3.png)   
   
위 그림은 양방향으로 통신하고 있는 두 호스트의 상황을 묘사한 것이다.   
상황은 이렇다. 호스트 A가 마지막 데이터를 전송하고 나서 close 함수의 호출을 통해서 연결을 종료하였다.   
때문에 그 이후부터 호스트 A는 호스트 B가 전송하는 데이터를 수신하지 못한다.   
데이터 수신과 관련된 함수의 호출 자체가 불가능하다.   
때문에 결국엔 호스트 B가 전송한, 호스트 A가 반드시 수신해야 할 데이터라 할지라도 그냥 소멸되고 만다.   
   
이러한 문제의 해결을 위해서 데이터의 송수신에 사용되는 `일부만 종료(Half-close)`하는 방법이 제공되고 있다.   
일부를 종료한다는 것은 전송은 가능하지만 수신은 불가능한 상황, 혹은 수신은 가능하지만 전송은 불가능한 상황을 뜻한다.   
말 그대로 스트림의 반만 닫는 것이다.   

### 소켓과 스트림(Stream)   

소켓을 통해서 두 호스트가 연결되면, 그 다음부터는 상호간에 데이터의 송수신이 가능한 상태가 된다.   
그리고 바로 이러한 상태를 가리켜 `스트림이 형성된 상태`라 한다.   
즉, 두 소켓이 연결되어서 데이터 송수신이 가능한 상태를 일종의 스트림으로 보는 것이다.   
스트림은 물의 흐름을 의미한다. 그런데 물의 흐름은 한쪽 방향으로만 형성된다.   
마찬가지로 소켓의 스트림 역시 한쪽 방향으로만 데이터의 이동이 가능하기 때문에 양방향 통신을 위해서는 다음 그림에서 보이듯이 두 개의 스트림이 필요하다.   
   
![소켓을 기반으로 생성되는 두 개의 스트림](https://user-images.githubusercontent.com/46395776/98442965-a33ed580-214b-11eb-8b98-8f42afeb1e05.png)   
   
때문에 두 호스트간에 소켓이 연결되면, 각 호스트 별로 입력 스트림과 출력 스트림이 형성된다.   
물론 한 호스트의 입력 스트림은 다른 호스트의 출력 스트림으로 이어지고, 한 호스트의 출력 스트림은 다른 호스트의 입력 스트림으로 이어진다.   
그리고 여기서 다루고자 하는 `우아한 종료`라는 것은 한 번에 이 두 스트림을 모두 끊어버리는 것이 아니라, 이 중 하나의 스트림만 끊는 것이다.   
물론, 리눅스의 close 함수와 윈도우의 closesocket 함수는 두 가지 스트림을 동시에 끊어버리기 때문에 우아한 연결종료와는 거리가 멀다.   

### 우아한 종료를 위한 shutdown 함수   

우아한 종료, 즉 Half-close에 사용되는 함수를 소개한다.   
다음 shutdown 함수가 스트림의 일부를 종료하는데 사용되는 함수이다.   
   
`int shutdown(int sock, int howto);`   

- sock : 종료할 소켓의 파일 디스크립터 전달.
- howto : 종료 방법에 대한 정보 전달.   
   
위의 함수 호출 시 두 번째 매개변수에 전달되는 인자에 따라서 종료의 방법이 결정된다.   
두 번째 매개변수에 전달될 수 있는 인자의 종류는 다음과 같다.   
   
- SHUT_RD : 입력 스트림 종료
- SHUT_WR : 출력 스트림 종료
- SHUT_RDWR : 입출력 스트림 종료   
   
shutdown 함수의 두 번째 인자로 SHUT_RD가 전달되면 입력 스트림이 종료되어 더 이상 데이터를 수신할 수 없는 상태가 된다.   
혹 데이터가 입력버퍼에 전달되더라도 그냥 지워져 버릴 뿐만 아니라 입력 관련 함수의 호출도 더 이상은 허용이 안 된다.   
   
반면 SHUT_WR가 두 번째 인자로 전달되면 출력 스트림이 종료되어 더 이상의 데이터 전송이 불가능해진다.   
단! 출력 버퍼에 아직 전송되지 못한 상태로 남아 있는 데이터가 존재하면 해당 데이터는 목적지로 전송된다.   
   
마지막으로 SHUT_RDWR가 전달되면 입력 스트림과 출력 스트림이 모두 종료되는데, 이는 shutdown 함수를 한 번은 SHUT_RD를 인자로, 또 한 번은 SHUT_WR을 인자로 두 번 호출한 것과 같다.   

### Half-close가 필요한 이유   

소켓의 반만 닫는다는 것에 대한 의미는 앞서 충분히 이해했다. 그러나 아직 풀어야 할 궁금증이 남아 있다.   
   
- Half-close가 도대체 왜 필요한가? 그냥 데이터를 주고받기에 충분한 만큼 연결을 유지했다가 종료하면 되는 것 아닌가? 급히 종료하지만 않으면 Half-close가 필요하지는 않을 것 같다.   
   
위의 의문은 전혀 틀린 말은 아니다.   
충분한 시간적 여유를 둬서 송수신을 완료하고 난 다음에 연결을 종료해도 되는 상황에서는 굳이 Half-close를 활용할 필요가 없다.   
그러나 다음과 같은 상황을 생각해보자.   
   
- 클라이언트가 서버에 접속하면 서버는 약속된 파일을 클라이언트에게 전송하고, 클라이언트는 파일을 잘 수신했다는 의미로 문자열 "Thank you"를 서버에 전송한다.   
   
여기서 문자열 "Thank you"의 전달은 사실상 불필요한 일이지만, 연결종료 직전에 클라이언트가 서버에 전송해야 할 데이터가 존재하는 상황으로 확대해석하자.   
그런데 이 상황에 대한 프로그램의 구현도 그리 간단하지만은 않다.   
파일을 전송하는 서버는 단순히 파일 데이터를 연속해서 전송하면 되지만, 클라이언트는 언제까지 데이터를 수신해야 할지 알 수 없기 때문이다.   
클라이언트 입장에서는 무턱대고 계속해서 입력 함수를 호출할 수도 없는 노릇이다.   
그랬다가는 블로킹 상태(호출된 함수가 반환하지 않는 상태)에 빠질 수 있기 때문이다.   
   
- 서버와 클라이언트 사이에 파일의 끝을 의미하는 문자 하나를 약속하면 되지 않는가?   
   
이것도 어울리지 않는 상황이다.   
약속으로 정해진 문자와 일치하는 데이터가 파일 내부에 존재할 수 있기 때문이다.   
이러한 문제의 해결을 위해서 서버는 파일의 전송이 끝났음을 알리는 목적으로 `EOF`를 마지막에 전송해야 한다.   
클라이언트는 EOF의 수신을 함수의 반환 값을 통해서 확인이 가능하기 때문에 파일에 저장된 데이터와 중복될 일도 없다.   
그럼 이제 남은 문제는 하나다. 서버는 어떻게 EOF를 전달할 수 있을까?   
   
- 출력 스트림을 종료하면 상대 호스트로 EOF가 전송된다.   
   
물론 close 함수 호출을 통해서 입출력 스트림을 모두 종료해줘도 EOF는 전송되지만, 이럴 경우 상대방이 전송하는 데이터를 더 이상 수신 못한다는 문제가 있다.   
즉, close 함수 호출을 통해서 스트림을 종료하면 클라이언트가 마지막으로 보내는 문자열 "Thank you"를 수신할 수 없다.   
따라서 shutdown 함수 호출을 통해서 서버의 출력 스트림만 Half-close해야 하는 것이다.   
이럴 경우 EOF도 전송되고 입력 스트림은 여전히 살아있어서 데이터의 수신도 가능하다.   
   
   
   #
# Domain Name System   

### 도메인 이름이란?   

인터넷에 서비스를 제공하는 서버들 역시 IP 주소로 구분이 된다.   
그러나 기억하기 쉽지 않은 IP 주소의 형태로 서버의 주소 정보를 기억하는 것은 사실상 불가능한 일이다.   
때문에, 기억하기도 좋고 표현하기도 좋은 형태의 도메인 이름이라는 것을 IP 주소에 부여해서, 이것이 IP 주소를 대신하도록 하고 있다.   

### DNS 서버   

인터넷 브라우저 주소 창에 네이버의 IP 주소인 `125.209.222.141(2020.11.08 기준)`를 직접 입력하면 네이버의 메인 페이지를 볼 수 있다.   
그러나 일반적으로는 네이버의 도메인 이름인 `www.naver.com`의 입력을 통해서 네이버에 접속한다.   
그렇다면 이 두 접속방법에는 어떠한 차이점이 있는 것일까?   
   
네이버의 메인 페이지에 접속한다는 점에서는 차이가 없지만, 접속의 과정에는 차이가 있다.   
도메인 이름은 해당 서버에 부여된 가상의 주소이지 실제 주소가 아니다.   
때문에 가상의 주소를 실제 주소로 변환하는 과정을 거쳐서 네이버에 접속해야 한다.   
그렇다면 어떻게 도메인 이름을 IP 주소로 변환해야 할까?   
이러한 변환을 담당하는 것이 DNS 서버이니, DNS 서버에게 다음과 같이 변환을 요청하면 된다.   
   
- DNS 서버야 www.naver.com의 IP 주소가 어떻게 되니?   
   
모든 컴퓨터에는 디폴트 DNS 서버의 주소가 등록되어 있는데, 바로 이 디폴트 DNS 서버를 통해서 도메인 이름에 대한 IP 주소 정보를 얻게 된다.   
즉, 우리가 인터넷 브라우저 주소 창에 도메인 이름을 입력하면 인터넷 브라우저는 해당 도메인 이름의 IP 주소를 디폴트 DNS 서버를 통해 얻게 되고, 그 다음에야 비로소 서버로의 실제 접속에 들어가게 되는 것이다.   
   
물론, 우리의 컴퓨터에 설정되어 있는 디폴트 DNS 서버가 모든 도메인의 IP 주소를 알고 있지는 않다.   
그러나 디폴트 DNS 서버는 모르면 물어서라도 가르쳐준다. 다른 DNS 서버에게 물어서라도 가르쳐준다.   
   
![DNS와 IP 주소의 요청](https://user-images.githubusercontent.com/46395776/98450180-00537f00-217e-11eb-83eb-767f954caf0a.png)   
   
위 그림은 호스트가 문의한 도메인 이름의 IP 주소를 디폴트 DNS 서버가 모르는 상황에 대한 응답 과정을 보이고 있다.   
이 그림에서 보이듯이 디폴트 DNS 서버는 자신이 모르는 정보에 대한 요청이 들어오면 한 단계 상위 계층에 있는 DNS 서버에게 물어본다.   
이러한 식으로 계속 올라가다 보면 최상위 DNS 서버인 Root DNS 서버에게까지 질의가 전달되는데, Root DNS 서버는 해당 질문을 누구에게 재 전달해야 할지 알고 있다.   
그래서 자신보다 하위에 있는 DNS 서버에게 다시 질의를 던져서 결국은 IP 주소를 얻어내며, 그 결과는 질의가 진행된 반대 방향으로 전달이 되어 결국에는 질의를 시작한 호스트에게 IP 주소가 전달된다.   
이렇듯 DNS는 계층적으로 관리되는 일종의 분산 데이터베이스 시스템이다.   

### 도메인 이름이 필요한 이유   

단순히 사용자 관점에서 외우기 쉬운 문자열 형태로 IP 주소 관리를 한다는 장점 뿐만 아니라 프로그래머의 관점에서도 얘기해 보자.   
만일 우리가 `www.kyomin.com`이라는 도메인을 운영하는 회사의 시스템 엔지니어라고 가정해 보자.   
그리고 우리는 회사의 서비스 사용을 위한 클라이언트 프로그램을 개발해야 한다.   
이 클라이언트 프로그램은 다음 주소의 서버에 접속해서 서비스를 받도록 설계되어 있다.   
   
- IP : 125.178.20.116
- PORT : 8080   
   
프로그램 사용자에게는 매우 편리한 실행 방법을 제공해야 한다.   
때문에 우리가 예제 실행하듯이 콘솔창에서 IP와 PORT 정보를 입력하면서 프로그램을 실행하게끔 구현하면 안 된다.   
그렇다면 위의 주소 정보를 어떻게 프로그램 내에 전달해야겠는가?   
이들 주소 정보를 프로그램 코드에 직접 삽입할 텐가?   
물론 이렇게 하면 편리한 프로그램의 실행은 가능하다. 하지만 이는 문제의 소지를 지니고 있다. 우리가 시스템을 운영하는 동안에 IP 주소를 계속 유지하는 것이 쉬운 일은 아니다.   
특히 `ISP(Internet Service Provider)` 서비스를 제공하는 통신 사업자의 도움으로 IP를 유지하고 있다면, 시스템과 관련된 여러 가지 이유로 IP 주소의 변경은 언제든지 발생할 수 있다.   
물론 ISP 사업자는 IP의 유지를 약속하겠지만, 이를 근거로 프로그램을 작성할 수는 없는 일이다.   
혹시라도 주소 정보가 변경되면 서비스 가입자들에게 다음과 같이 이야기해야 할지도 모른다.   
   
- 지금 사용하는 프로그램은 다 지우고, 홈페이지에 가서 v1.2를 다운 받아 재설치 하십시오!   
   
아니, 언제 또 주소 정보가 바뀔지 모르니 그냥 소스코드를 주고서 필요할 때마다 IP와 PORT 번호를 바꿔서 컴파일해서 쓰라고 하는게 나을 수도 있다.   
`IP 주소는 도메인 이름에 비해 상대적으로 변경의 확률이 높다.`   
때문에 IP 주소를 바탕으로 프로그램을 작성하는 것은 좋은 방법이 아니다.   
그렇다면 어떤 방법을 생각할 수 있을까?   
도메인 이름은 일단 등록하고 나면 평생 유지가 가능하니, 이를 이용해서 코드를 작성하는 편이 나을 수 있다.   
이렇게 되면 프로그램이 실행될 때마다 도메인 이름을 근거로 IP 주소를 얻어온 다음에 서버에 접속을 하게 되니, 서버의 IP 주소로부터 클라이언트 프로그램은 자유로울 수 있다.   
그래서 IP 주소와 도메인 이름 사이의 변환 함수가 필요한 것이다.   
   
   
   #
# 프로세스의 이해와 활용   

### 두 가지 유형의 서버   

지금까지 위에서 공부한 내용만 가지고, 연결요청의 순서를 따져서 첫 번째 클라이언트로부터 백 번째 클라이언트까지 순차적으로 연결을 허용해서 서비스를 제공하는 `일렬종대 서비스` 서버는 만들 수 있다.   
물론 첫 번째로 접속한 클라이언트는 이 서버에 불만이 없겠지만, 불과 0.5초 차이로 순서가 100번대로 밀린 클라이언트는 불만이 많을 것이다.   
   
진정으로 클라이언트를 생각한다면 모든 클라이언트의 만족도를 평균 이상으로 끌어올려야 한다.   
다음 유형의 서버가 있다면 사람들은 만족을 할까?   
   
- 첫 번째 연결 요청자의 접속 대기 시간은 0초, 50번째 연결 요청자의 접속 대기 시간은 50초 그리고 100번째 연결 요청자의 접속 대기 시간은 100초입니다. 그러나 일단 연결만 되면 1초 안에 서비스를 완료해 드립니다.
   
물론, 연결 요청의 순서가 다섯 손가락 안에 든다면 서비스에 대한 만족도는 높을 것이다.   
그러나 이를 넘어선다면 클라이언트의 불만은 매우 높을 수밖에 없다.   
이럴 바에는 다음의 형태로 서비스를 제공하는 편이 낫다.   
   
- 모든 연결 요청자의 접속 대기 시간은 1초를 넘기지 않습니다. 그러나 서비스를 제공 받는데 걸리는 시간은 평균적으로 2 ~ 3초 정도 걸립니다.
   
위의 둘 중에서 어떠한 유형의 서버가 좋은지 많이 고민할 필요가 없다.   
현재 페이지(github.com/kyomin)에 접속한 여러분의 연결 요청 순번이 100번 대에(이 정도로 kyomin의 repository가 인기 있다고 가정) 있다고 생각해 보면 금세 답이 나올 것이다.   
앞의 99명이 페이지 이용을 끝마칠 때까지 기다려야 하는 상황이 생기기 때문이다.   

### 다중접속 서버의 구현 방법들   

위에서 살펴봤듯이 전체적인 서비스 제공 시간이 조금 늦어지더라도, 연결 요청을 해오는 모든 클라이언트에게 동시에 서비스를 제공해서 평균적인 만족도를 높일 필요가 있다.   
그리고 네트워크 프로그램은 CPU의 연산을 필요치 않는 데이터의 송수신 시간이 큰 비중을 차지하므로, 둘 이상의 클라이언트에게 동시에 서비스를 제공하는 것이 CPU를 보다 효율적으로 사용하는 방법이 된다.   
때문에 우리는 둘 이상의 클라이언트에게 동시에 서비스를 제공하는 `다중접속 서버`에 대해 논의하고자 한다.   
다음은 대표적인 다중접속 서버의 구현 모델 및 구현 방법이다.   
   
- 멀티프로세스 기반 서버 : 다수의 프로세스를 생성하는 방식으로 서비스 제공
- 멀티플렉싱 기반 서버 : 입출력 대상을 묶어서 관리하는 방식으로 서비스 제공
- 멀티쓰레딩 기반 서버 : 클라이언트의 수만큼 쓰레드를 생성하는 방식으로 서비스 제공
   
### 프로세스(Process)의 이해   

프로세스는 간단히 다음과 같이 정의할 수 있다.   
   
- 메모리 공간을 차지한 상태에서 실행 중인 프로그램   
   
일단, 로컬 디스크에 저장된 프로그램을 실행하면 `메인 메모리(Main Memory, RAM)`라는 곳으로 프로그램이 이동한다.   
바로 이 시점부터 프로세스라 부를 수 있게 된다.   
여기에 올라온 프로그램을 위해 운영체제는 스택, 힙, 데이터 영역과 같은 메모리 공간을 할당하고, 프로그램 코드를 실행하며 CPU는 해당 프로그램을 위한 연산을 진행한다.   
그 과정에서 CPU에는 프로그램의 여러 값을 연산하고 저장하기 위한 `레지스터(Register)`를 할당한다.   
즉, 이렇게 실행 중인 프로그램에 관련된 메모리, 리소스 등을 총칭하는 의미로 프로세스를 정의하기도 한다.   
   
더불어 위의 정의에 의해 A 프로그램을 실행하면 A 프로그램이 메인 메모리에 올라가게 되고, A 프로세스라 불리게 된다.   
그러면 CPU에는 A를 위한 정보들로 채워질 것이다.   
그런데 갑자기 B 프로세스를 실행하게 되면 B의 실행을 위해 해당 정보들을 CPU에 올리게 된다.   
이를 위해 기존의 A 정보들은 하드 디스크에 임시 저장한다.   
이렇게 프로세스 간 작업 전환을 가리켜 `문맥 교환, 컨텍스트 스위칭(Context Switching)`이라 한다.   
이를 통해 하나의 싱글 CPU로도 여러 프로세스를 무리 없이 동시에 실행하는 효과를 보는 것이다.   
하지만 이는 비용이 비싸다.   

### CPU의 코어 수와 프로세스 수   

두 개의 연산장치가 존재하는 CPU를 가리켜 듀얼(Dual) 코어 CPU라 하고, 네 개의 연산장치가 존재하는 CPU를 가리켜 쿼드(Quad) 코어 CPU라 한다.   
이렇듯 CPU에는 실제 연산장치에 해당하는 코어가 둘 이상 존재할 수 있으며, 코어의 수만큼 프로세스는 동시 실행이 가능하다.   
   
반면, 코어의 수를 넘어서는 개수의 프로세스가 생성되면, 프로세스 별로 코어에 할당되는 시간이 나뉘게 된다.   
그러나 CPU가 고속으로 프로세스를 실행하기 때문에 우리는 모든 프로세스가 동시에 실행되는 것처럼 느끼게 된다.   
물론 코어의 수가 많을수록 그 느낌은 더할 것이다.   

### fork 함수 호출을 통한 프로세스의 생성   

프로세스의 생성에는 몇 가지 방법이 있다.   
여기서는 멀티프로세스 기반 서버의 구현에 사용되는 fork 함수에 대해 설명한다.   
   
`pid_t fork(void);`   

- 성공 시 프로세스 ID, 실패 시 -1 반환   
   
fork 함수는 호출한 프로세스의 복사본을 생성한다(사실 이게 개념적으로 조금 어렵다).   
즉, 전혀 새로운 다른 프로그램을 바탕으로 프로세스를 생성하는 것이 아니라 이미 실행중인, fork 함수를 호출한 프로세스를 복사하는 것이다.   
그리고는 두 프로세스 모두 fork 함수의 호출 이후 문장을 실행하게 된다(정확히 표현하면 fork 함수의 반환 이후).   
그런데 완전히 동일한 프로세스로, 메모리 영역까지 동일하게 복사하기 때문에 이후의 프로그램 흐름은 fork 함수의 반환 값을 기준으로 나뉘도록 프로그래밍을 해야 한다.   
즉, fork 함수는 다음 특징을 이용해서 프로그램의 흐름을 구분해야 한다.   
   
- 부모 프로세스 : fork 함수의 반환 값은 자식 프로세스의 ID
- 자식 프로세스 : fork 함수의 반환 값은 0   
   
여기서 `부모 프로세스(Parent Process)`란 원본 프로세스, 즉, fork 함수를 호출한 주체가 된다.   
반면 `자식 프로세스(Child Process)`는 부모 프로세스의 fork 함수 호출을 통해서 복사된 프로세스를 의미한다.   
그럼 간단히 fork 함수의 호출 이후 실행의 흐름을 정리해 보겠다.   
   
![fork 함수의 호출](https://user-images.githubusercontent.com/46395776/98525241-8f19e600-22bb-11eb-92d3-c215155709b3.png)   
   
위 그림에서 보이듯이 부모 프로세스가 fork 함수를 호출하는 순간 자식 프로세스가 복사되어 각각이 fork 함수 호출의 반환 값을 받게 된다.   
그런데 복사 이전에 부모 프로세스가 `전역변수 gval`의 값을 11로, `지역변수 lval`의 값을 25로 증가시켰기 때문에 증가된 상태로 복사가 이뤄진다.   
다만 fork 함수의 반환 값의 차로 인해서 부모 프로세스는 lval의 값을 1 증가시키지만, 이는 자식 프로세스의 lval에 영향을 미치지 않는다.   
마찬가지로 자식 프로세스는 gval의 값을 1 증가시키지만, 이는 부모 프로세스의 gval에 영향을 미치지 않는다.   
fork 함수 호출 이후에는 두 프로세스가 동일한 코드를 실행하는 완전히 다른 프로세스가 되기 때문이다.   
   
   
   #
# 프로세스 & 좀비(Zombie) 프로세스   

### 좀비(Zombie) 프로세스   

프로세스가 생성되고 나서 할 일을 다 하면(main 함수의 실행을 완료하면) 사라져야 하는데, 사라지지 않고 좀비가 되어 시스템의 중요한 리소스를 차지하기도 한다.   
이 상태에 있는 프로세스를 가리켜 `좀비 프로세스`라 하는데, 이는 시스템에 부담을 주는 원인이 되기도 한다.   
때문에 우리는 좀비 프로세스를 소멸시켜야 한다.   

### 좀비 프로세스의 생성 이유   

좀비 프로세스의 생성을 막기에 앞서 좀비 프로세스의 생성 이유를 먼저 살펴보자.   
fork 함수의 호출로 생성된 자식 프로세스가 종료되는 상황 두 가지를 예로 들면 다음과 같다.   
   
- 인자를 전달하면서 exit을 호출하는 경우
- main 함수에서 return문을 실행하면서 값을 반환하는 경우   
   
exit 함수로 전달되는 인자 값과 main 함수의 return문에 의해 반환되는 값 모두 운영체제로 전달된다.   
그리고 운영체제는 이 값이 자식 프로세스를 생성한 부모 프로세스에게 전달될 때까지 자식 프로세스를 소멸시키지 않는데, 바로 이 상황에 놓여있는 프로세스를 가리켜 좀비 프로세스라 한다.   
즉, 자식 프로세스를 좀비 프로세스로 만드는 주체는 운영체제이다.   
그렇다면 이 좀비 프로세스는 언제 소멸이 될까?   
   
- 해당 자식 프로세스를 생성한 부모 프로세스에게 exit 함수의 인자 값이나 return문의 반환 값이 전달되어야 한다.   
   
그렇다면 어떻게 부모 프로세스에게 값을 전달해야 할까?   
부모 프로세스가 가만히 있는데 운영체제가 알아서 값을 전달해주지는 않는다.   
부모 프로세스의 적극적인 요청이 있어야(함수 호출이 있어야) 운영체제는 값을 전달해 준다.   
   
반대로 말하면 부모 프로세스가 자식 프로세스의 전달 값을 요청하지 않으면, 운영체제는 그 값을 계속해서 유지하게 되고 결국 자식 프로세스는 좀비의 상태로 오랫동안 머물러 있어야 한다.   
결국 부모가 책임지고 자신이 낳은 자식을 거둬들여야 하는 셈이다.   

### 좀비 프로세스의 소멸1 : wait 함수의 사용   

자식 프로세스의 소멸을 위해서는 부모 프로세스가 자식 프로세스의 전달 값을 요청해야 함을 알았으니, 이제 요청을 위한 구체적인 방법을 알아보도록 하자.   
다행히도 요청 방법은 매우 쉽다.   
요청에는 두 가지 방법이 있는데, 그 중 하나는 다음 함수를 호출하는 것이다.   
   
`pid_t wait(int* statloc);`   

- 성공 시 종료된 자식 프로세스의 ID, 실패 시 -1 반환.
   
위 함수가 호출되었을 때, 이미 종료된 자식 프로세스가 있다면, 자식 프로세스가 종료되면서 전달한 값(exit 함수의 인자 값, main 함수의 return에 의한 반환 값)이 매개변수로 전달된 주소의 변수에 저장된다.   
그런데 이 변수에 저장되는 값에는 자식 프로세스가 종료되면서 전달한 값 이외에도 다른 정보가 함께 포함되어 있으니, 다음 매크로 함수를 통해서 값의 분리 과정을 거쳐야 한다.   
   
- WIFEXITED : 자식 프로세스가 정상 종료한 경우 `참(true)`을 반환한다.
- WEXITSTATUS : 자식 프로세스의 전달 값을 반환한다.
   
즉, wait 함수의 인자로 변수 status의 주소 값이 전달되었다면, wait 함수의 호출 이후에는 다음과 같은 유형의 코드를 구성해야 한다.   
   
<pre>
<code>

// 정상 종료하였는가?
if(WIFEXITED(status)) {
	puts("Normal termination!");
	printf("Child pass num: %d", WEXITSTATUS(status));	// 그렇다면 반환 값은?
}

</code>
</pre>   
   
참고로 wait 함수는 호출된 시점에서 종료된 자식 프로세스가 없다면, 임의의 자식 프로세스가 종료될 때까지 `블로킹(Blocking)` 상태에 놓인다는 특징이 있다.   
때문에 함수의 호출에 주의해야 한다.   

### 좀비 프로세스의 소멸2: waitpid 함수의 사용   

wait 함수의 블로킹이 문제가 된다면 `waitpid` 함수의 호출을 고려하면 된다.   
이는 좀비 프로세스의 생성을 막는 두 번째 방법이자 블로킹 문제의 해결책이기도 하다.   
   
`pid_t waitpid(pid_t pid, int* statloc, int options);`   

- pid : 종료를 확인하고자 하는 자식 프로세스의 ID 전달. 이를 대신해서 -1을 전달하면 wait 함수와 마찬가지로 임의의 자식 프로세스가 종료되기를 기다린다.
- statloc : wait 함수의 매개변수 statloc과 동일한 의미로 사용된다.
- options : 헤더파일 sys/wait.h에 선언된 상수 WNOHANG을 인자로 전달하면, 종료된 자식 프로세스가 존재하지 않아도 블로킹 상태에 있지 않고, 0을 반환하면서 함수를 빠져나온다.   
   
   
   #
# 시그널 핸들링   

### 운영체제야! 네가 좀 알려줘   

자식 프로세스 종료의 인식 주체는 운영체제이다.   
따라서 운영체제가 열심히 일하고 있는 부모 프로세스에게 다음과 같이 이야기해줄 수 있다면 효율적인 프로그램의 구현이 가능하다.   
   
- 어이, 부모 프로세스! 네가 생성한 자식 프로세스가 종료되었다!   
   
그러면 부모 프로세스는 하던 일을 잠시 멈추고, 자식 프로세스의 종료와 관련된 일을 처리하면 된다.   
이상적이고도 멋진 시나리오다. 이러한 시나리오의 프로그램 구현을 위해서 `시그널 핸들링(Signal Handling)`이라는 것이 존재한다.   
여기서 `시그널`은 특정 상황이 발생했음을 알리기 위해 운영체제가 프로세스에게 전달하는 메시지를 의미한다.   
그리고 그 메시지에 반응해서 메시지와 연관된, 미리 정의된 작업이 진행되는 것을 가리켜 `핸들링` 또는 `시그널 핸들링`이라 한다.   

### 시그널과 signal 함수   

다음은 시그널 핸들링의 이해를 돕기 위한 프로세스와 운영체제의 대화 내용이다.   
이 대화 안에 시그널 핸들링과 관련된 내용 전부가 들어있다.   
   
- 프로세스 : 야, 운영체제야! 내가 생성한 자식 프로세스가 종료되면 zombie handler라는 이름의 함수 좀 호출해 주라!
- 운영체제 : 그래! 그럼 네가 생성한 자식 프로세스가 종료되면, 네가 말한 zombie_handler라는 이름의 함수를 내가 대신 호출해줄 테니, 그 상황에서 실행해야 할 문장들을 그 함수에 잘 묶어둬!   
   
위의 대화 중에서 프로세스가 한 이야기가 `시그널 등록`에 해당한다.   
즉, 프로세스는 자식 프로세스의 종료라는 상황 발생 시, 특정 함수의 호출을 운영체제에게 요구하는 것이다.   
이 요구는 다음 함수의 호출을 통해서 이뤄진다(때문에 이 함수를 시그널 등록 함수라 표현한다).   
   
`void (*signal(int signo, void (*func)(int)))(int);`   

- 시그널 발생 시 호출되도록 이전에 등록된 함수의 포인터 반환   
   
위의 함수 선언은 다음과 같이 정리할 수 있다.   
   
- 함수 이름 : signal
- 매개변수 선언 : int signo, void(*func)(int)
- 반환형 : 매개변수형이 int이고 반환형이 void인 함수 포인터   
   
위 함수를 호출하면서 첫 번째 인자로 특정 상황에 대한 정보를, 두 번째 인자로 특정 상황에서 호출될 함수의 주소 값(포인터)을 전달한다.   
그러면 첫 번째 인자를 통해 명시된 상황 발생 시, 두 번째 인자로 전달된 주소 값의 함수가 호출된다.   
참고로 signal 함수를 통해서 등록 가능한 특정 상황과 그 상황에 할당된 상수 몇몇을 정리해보면 다음과 같다.   
   
- SIGALRM : alarm 함수 호출을 통해서 등록된 시간이 다 된 상황
- SIGINT : CTRL + C가 입력된 상황
- SIGCHLD : 자식 프로세스가 종료된 상황   
   
자! 그럼 다음 요청에 해당하는 signal 함수의 호출 문장을 만들어 보겠다.   
   
- 자식 프로세스가 종료되면 mychild 함수를 호출해 달라.   
   
이때, mychild 함수는 매개변수형이 int이고, 반환형이 void이어야 한다.   
그래야 signal 함수의 두 번째 전달인자가 될 수 있다.   
그리고 자식 프로세스가 종료된 상황은 상수 SIGCHILD로 정의되어 있으니, 이것이 signal 함수의 첫 번째 인자가 되어야 한다.   
즉, signal 함수의 호출 문장은 다음과 같이 구성하면 된다.   
   
- signal(SIGCHLD, mychild);   
   
그럼 이번에는 다음 두 가지 요청에 해당하는 signal 함수의 호출 문장을 각각 만들어 보겠다.   
   
- alarm 함수 호출을 통해서 등록된 시간이 지나면 timeout 함수를 호출해 달라.
- CTRL + C가 입력되면, keycontrol 함수를 호출해 달라.   
   
이들 각각의 상황에 할당된 상수의 이름이 SIGALRM, SIGINT이니, 다음과 같이 signal 함수의 호출 문장을 구성하면 된다.   
   
- signal(SIGALRM, timeout);
- signal(SIGINT, keycontrol);   
   
이렇게 시그널이 등록되면, 등록된 시그널 발생 시(등록된 상황 발생 시), 운영체제는 해당 시그널에 등록된 함수를 호출해준다.   
다음은 alarm 함수를 소개한다.   
   
`unsigned int alarm(unsigned int seconds);`   

- 0 또는 SIGALRM 시그널이 발생하기까지 남아있는 시간을 초 단위로 반환
   
위 함수를 호출하면서 양의 정수를 인자로 전달하면, 전달된 수에 해당하는 시간(초 단위)이 지나서 SIGALRM 시그널이 발생한다.   
그리고 0을 인자로 전달하면 이전에 설정된 SIGALRM 시그널 발생의 예약이 취소된다.   
그런데 위의 함수 호출을 통해서 시그널의 발생을 예약만 해놓고, 이 시그널이 발생했을 때 호출되어야 할 함수를 지정하지 않으면(signal 함수 호출을 통해서) 프로세스가 그냥 종료되어 버리니 이를 주의해야 한다.   

### sigaction 함수를 이용한 시그널 핸들링   

지금까지 설명한 내용만 가지고도 좀비 프로세스의 생성을 막는 코드를 충분히 만들어 낼 수 있다.   
그러나 함수를 하나 더 소개하고자 한다.   
이번에 소개할 `sigaction` 함수는 signal 함수와 유사사다.   
아니, signal 함수를 대체할 수 있고, 또 signal 함수보다 훨씬 안정적으로 동작한다.   
안정적으로 동작하는 이유는 다음과 같다.   
   
- signal 함수는 유닉스 계열의 운영체제 별로 동작 방식에 있어서 약간의 차이를 보일 수 있지만, sigaction 함수는 차이를 보이지 않는다.   
   
실제로 요즘은 signal 함수를 사용해서 프로그램을 작성하지 않는다.   
이 함수는 과거 프로그램과의 호환성을 위해서 유지만 되고 있을 뿐이다.   
그래서 sigaction 함수에 대해 소개하고자 하는데, 앞서 설명한 signal 함수의 기능을 대신할 수 있는 수준으로만 설명한다.   
   
`int sigaction(int signo, const struct* act, struct sigaction* oldact);`   

- signo : signal 함수와 마찬가지로 시그널의 정보를 인자로 전달.
- act : 첫 번째 인자로 전달된 상수에 해당하는 시그널 발생 시 호출될 함수(시그널 핸들러)의 정보 전달.
- oldact : 이전에 등록되었던 시그널 핸들러의 함수 포인터를 얻는데 사용되는 인자. 필요 없다면 0 전달.
   
위 함수의 호출을 위해서는 sigaction이라는 이름의 구조체 변수를 선언 및 초기화해야 하는데, 이 구조체는 다음과 같이 정의되어 있다.   
   
<pre>
<code>

struct sigaction
{
	void (*sa_handler)(int);
	sigset_t sa_mask;
	int sa_flags;
}

</code>
</pre>   
   
위의 구조체 멤버 중에서 sa_handler에 시그널 핸들러의 함수 포인터 값(주소 값)을 저장하면 된다.   
그리고 sa_mask는 모든 비트를 0으로, sa_flags는 0으로 초기화한다.   
이 두 멤버는 시그널 관련 옵션 및 특성의 지정에 사용되는데, 우리의 목적은 좀비 프로세스의 생성을 막는데 있으므로 이 두 멤버에 대한 설명은 생략한다.   
   
   
   #
# 멀티태스킹 기반의 다중접속 서버   

### 프로세스 기반의 다중접속 서버의 구현 모델   

이전에 구현했던 에코 서버는 한 번에 하나의 클라이언트에게만 서비스를 제공할 수 있었다.   
즉, 동시에 둘 이상의 클라이언트에게 서비스를 제공하지 못하는 구조였다.   
따라서 이번에는 동시에 둘 이상의 클라이언트에게 서비스를 제공하는 형태로 에코 서버를 확장해 보겠다.   
다음 그림은 멀티 프로세스 기반의 다중접속 에코 서버의 구현 모델을 보이고 있다.   
   
![다중접속 서버모델](https://user-images.githubusercontent.com/46395776/98611938-5ec35d80-2336-11eb-9c10-3c7f7431345d.png)   
   
위 그림에서 보이듯이 클라이언트의 서비스 요청(연결 요청)이 있을 때마다 에코 서버는 자식 프로세스를 생성해서 서비스를 제공한다.   
즉, 서비스를 요청하는 클라이언트의 수가 다섯이라면 에코 서버는 추가로 다섯 개의 자식 프로세스를 생성해서 서비스를 제공한다.   
이를 위해서 에코 서버는 다음의 과정을 거쳐야 한다. 이것이 기존 에코 서버와의 차이점이다.   
   
- 1단계 : 에코 서버(부모 프로세스)는 accept 함수 호출을 통해서 연결 요청을 수락한다.
- 2단계 : 이때 얻게 되는 소켓의 파일 디스크립터를 자식 프로세스를 생성해서 넘겨준다.
- 3단계 : 자식 프로세스는 전달받은 파일 디스크립터를 바탕으로 서비스를 제공한다.   
   
여기서 다소 혼란스러운 부분은 자식 프로세스에게 소켓의 파일 디스크립터를 넘기는 방법이다.   
그러나 실제 코드상에서 이를 확인하면 이는 아무것도 아님을 알 수 있다.   
왜냐하면 자식 프로세스는 부모 프로세스가 소유하고 있는 것을 전부 복사하기 때문이다.   
즉, 사실상 파일 디스크립터를 넘기는 과정은 별도로 거칠 필요가 없다.   
이 예제 코드는 `echo_mpserv.c` 파일이다.   

### fork 함수 호출을 통한 파일 디스크립터의 복사   

`echo_mpserv.c` 소스 코드를 보면 fork 함수 호출을 통한 파일 디스크립터의 복사를 보여준다.   
부모 프로세스가 지니고 있던 두 소켓(하나는 서버 소켓, 또 하나는 클라이언트와 연결된 소켓)의 파일 디스크립터가 자식 프로세스에게 복사되었다.   
   
사실 파일 디스크립터의 복사는 다소 이해하기 힘든 부분이 있다.   
fork 함수가 호출되면 부모 프로세스의 모든 것이 복사되니 소켓도 함께 복사되었을 거라고 생각할 수 있다.   
그러나 소켓은 프로세스의 소유가 아니다. 엄밀히 말해서 운영체제의 소유이다.   
다만 해당 소켓을 의미하는 파일 디스크립터만이 프로세스의 소유인 것이다.   
그런데 굳이 이렇게 이해하지 않아도 소켓이 복사된다는 것은 다음의 이유로도 이치에 맞지 않는다.   
   
- 소켓이 복사되면 동일한 PORT에 할당된 소켓이 둘 이상이 된다.   
   
즉, 예제 `echo_mpserv.c`에서 fork 함수의 호출 결과는 다음 그림과 같다.   
fork 함수 호출 이후에 하나의 소켓에 두 개의 파일 디스크립터가 할당된 모습을 보인다.   
   
![fork 함수의 호출과 파일 디스크립터의 복사](https://user-images.githubusercontent.com/46395776/98627883-9d6a0f80-2358-11eb-9afb-a6ce255285f5.png)   
   
위 그림과 같이 하나의 소켓에 두 개의 파일 디스크립터가 존재하는 경우, 두 개의 파일 디스크립터가 모두 종료(소멸)되어야 소켓은 소멸된다.   
때문에 위의 그림과 같은 형태를 유지하면 이후에 자식 프로세스가 클라이언트와 연결되어 있는 소켓을 소멸하려 해도 소멸되지 않고 계속 남아있게 된다(이는 소버 소켓도 마찬가지이다).   
   
   
   #
# 프로세스간 통신의 기본 개념   

### 프로세스간 통신의 기본 이해   

프로세스간 통신이 가능하다는 것은 서로 다른 두 프로세스가 데이터를 주고 받을 수 있다는 의미가 되며, 이렇게 되기 위해서는 두 프로세스가 동시에 접근 가능한 메모리 공간이 있어야 한다.   
프로세스간 통신은 생각보다 어렵지 않은 개념이다.   
프로세스 A가 프로세스 B에게 다음과 같이 말한다면 이 역시 프로세스간 통신의 규칙이 된다.   
   
- 내게 빵이 하나 생기면 변수 bread의 값을 1로 변경하겠다. 그리고 그 빵을 먹어버리면 변수 bread의 값을 0으로 다시 변경하겠다. 그러니 너는 변수 bread의 값을 통해서 내 상태를 파악해라.   
   
즉, 프로세스 A는 변수 bread를 통해서 자신의 상태를 프로세스 B에게 말한 셈이고, 프로세스 B는 변수 bread를 통해서 프로세스 A가 한 말을 들은 셈이다.   
때문에 두 프로세스가 `동시에 접근 가능한 메모리 공간`만 있다면, 이 공간을 통해서 얼마든지 데이터를 주고 받을 수 있다.   
하지만 프로세스는 서로 완전히 별개의 메모리 구조를 지닌다.   
따라서 fork 함수 호출을 통해서 생성된 자식 프로세스조차 부모 프로세스와 메모리 공간을 조금도 공유하지 않는다.   
그래서 프로세스간 통신은 별도로 마련된 방법을 통해서만 이뤄질 수 있다.   

### 파이프(PIPE) 기반의 프로세스간 통신   

다음 그림은 프로세스간 통신의 방법으로 사용되는 파이프 기법의 구조적 모델을 보이고 있다.   
   
![파이프 기반 프로세스 통신 모델](https://user-images.githubusercontent.com/46395776/98629081-719c5900-235b-11eb-8df2-214f6e197039.jpeg)   
   
위 그림에서 보이듯이 두 프로세스간 통신을 위해서는 파이프라는 것을 생성해야 한다.   
이 파이프는 프로세스에 속하는 자원이 아니다. 이는 소켓과 마찬가지로 운영체제에 속하는 자원이다(때문에 fork 함수의 호출에 의한 복사 대상이 아니다).   
즉, 운영체제가 마련해 주는 메모리 공간을 통해서 두 프로세스는 통신을 하게 된다.   
그럼 먼저 파이프의 생성에 사용되는 함수를 소개한다.   
   
`int pipe(int filedes[2]);`   

- filedes[0] : 파이프로부터 데이터를 수신하는데 사용되는 파일 디스크립터가 저장된다. 즉, filedes[0]는 파이프의 출구가 된다.
- filedes[1] : 파이프로 데이터를 전송하는데 사용되는 파일 디스크립터가 저장된다. 즉, filedes[1]은 파이프의 입구가 된다.   
   
길이가 2인 int형 배열의 주소 값을 인자로 전달하면서 위의 함수를 호출하면 배열에는 두 개의 파일 디스크립터가 담긴다.   
그리고 이들 각각은 파이프의 출구와 입구로 사용이 된다.   
결국 부모 프로세스가 위의 함수를 호출하면 파이프가 생성되고, 파이프의 입구 및 출구에 해당하는 파일 디스크립터를 동시에 얻게 되는 것이다.   
따라서 부모 프로세스 혼자서 파이프 안으로 데이터를 집어넣고 꺼내는 것도 가능하다.   
그런데 부모 프로세스의 목적은 자식 프로세스와의 데이터 송수신이니, 입구 또는 출구에 해당하는 파일 디스크립터 중 하나를 자식 프로세스에게 전달해야 한다.   
   
   
   #
# IO 멀티플렉싱 기반의 서버   

### 멀티프로세스 서버의 단점과 대안   

멀티프로세스 기반의 서버에서는 다중접속 구현을 위해서 클라이언트의 연결 요청이 있을 때마다 새로운 프로세스를 생성하였다.   
이는 실제 사용되는 방법이지만 문제가 없는 것은 아니다.   
프로세스의 생성에는 상당히 많은 비용을 지불해야 하기 때문이다.   
많은 양의 연산이 요구되며, 필요한 메모리 공간도 비교적 큰 편이다.   
또한, 프로세스마다 별도의 메모리 공간을 유지하기 때문에 상호간에 데이터를 주고받으려면 다소 복잡한 방법을 택할 수밖에 없다(IPC는 다소 복잡한 통신방법이다).   
   
그렇다면 프로세스의 생성을 동반하지 않으면서 다수의 클라이언트에게 서비스를 제공할 수 있는 방법이 있을까?   
바로 IO 멀티플렉싱 서버가 바로 그것이다.   

### 멀티플렉싱의 개념과 서버에 적용하기   

멀티플렉싱이라는 단어는 전자 및 통신공학에서 매우 흔히 등장한다.   
개념적으로는 다음과 같다.   
   
- 하나의 통신채널을 통해서 둘 이상의 데이터(시그널)를 전송하는데 사용되는 기술   
   
간단히 하나의 리소스를 공유하는 여러 요청을 특정 기준으로 구분하는 기술이다.   
이를 적용한 서버 모델은 다음과 같다.   
   
![멀티플렉싱 서버](https://user-images.githubusercontent.com/46395776/98635936-2db05080-2369-11eb-982b-8bbc1390aaf3.jpg)   
   
멀티프로세스에서 멀티플렉싱 방식으로 변경하면 프로세스의 수가 줄어든 것을 볼 수 있다.   
여기서 중요한 것은 접속해있는 클라이언트의 수에 상관없이, 서비스를 제공하는 프로세스의 수는 딱 하나라는 사실이다.   
   
   
   #
# select 함수의 이해와 서버의 구현   

### select 함수의 기능과 호출 순서   

select 함수를 이용하는 것이 멀티플렉싱 서버의 구현에 있어서 가장 대표적인 방법이다.   
그리고 윈도우에도 이와 동일한 이름으로 동일한 기능을 제공하는 함수가 있기 때문에 이식성에 있어서도 좋은 점수를 줄 수 있다.   
   
select 함수를 사용하면 한 곳에 여러 개의 파일 디스크립터를 모아놓고 동시에 이들을 관찰할 수 있다.   
이때 관찰할 수 있는 항목은 다음과 같다.   
   
- 수신한 데이터를 지니고 있는 소켓이 존재하는가? (read)
- 블로킹되지 않고 데이터의 전송이 가능한 소켓은 무엇인가? (write)
- 예외상황이 발생한 소켓은 무엇인가?
   
그런데 select 함수는 사용 방법에 있어서 일반적인 함수들과 많은 차이를 보인다. 보다 정확히 표현하면 사용하기가 만만치 않다.   
그래도 멀티플렉싱 서버의 구현을 위해서는 select 함수를 잘 이해하고 이를 소켓에 적용해야 한다.   
다음 그림은 select 함수의 호출 방법과 순서를 보여준다.   
   
![select 함수의 호출 과정](https://user-images.githubusercontent.com/46395776/98670093-8564b100-2395-11eb-95ec-d0abb4162820.jpeg)   
   
위 그림은 select 함수를 호출해서 결과를 얻기까지의 과정을 간략히 정리한 것이다.   
그림에서는 select 함수의 호출에 앞서 뭔가 준비가 필요하고, 또 호출 이후에도 결과의 확인을 위한 별도의 과정이 존재함을 보이고 있다.   
이제 하나씩 그림에서 보이는 순서대로 살펴본다.   

### 파일 디스크립터의 설정   

select 함수를 사용하면 여러 개의 파일 디스크립터를 동시에 관찰할 수 있다고 하였다.   
물론 파일 디스크립터의 관찰은 소켓의 관찰로 해석할 수 있다.   
그렇다면 먼저 관찰하고자 하는 파일 디스크립터를 모아야 한다.   
모을 때도 관찰항목(수신, 전송, 예외)에 따라서 구분해서 모아야 한다.   
즉, 바로 위에서 언급한 세 가지 관찰 항목별로 구분해서 세 묶음으로 모아야 한다.   
파일 디스크립터를 세 묶음으로 모을 때 사용되는 것이 `fd_set`형 변수이다.   
이는 다음 그림에서 보이듯이 0과 1로 표현되는, 비트 단위로 이뤄진 배열이라고 생각하면 된다.   
   
![자료형 fd_set](https://user-images.githubusercontent.com/46395776/98670865-b1346680-2396-11eb-9b66-ea46a4a6cb18.jpeg)   
   
위 그림의 배열에서 가장 왼쪽 비트는 파일 디스크립터 0을 나타낸다(나타내는 위치이다).   
이 비트가 1로 설정되면 해당 파일 디스크립터가 관찰의 대상임을 의미한다.   
그렇다면 위 그림에서는 어떤 파일 디스크립터가 관찰 대상으로 지정되어 있는가?   
파일 디스크립터 0과 3이 관찰 대상으로 지정되어 있다.   
   
그럼 파일 디스크립터의 숫자를 확인해서 fd_set형 변수에 직접 값을 등록해야 할까?   
물론 아니다! fd_set형 변수의 조작은 비트 단위로 이뤄지기 때문에 직접 값을 등록하는 일은 여간 번거로운 일이 아닌데, 이를 프로그래머에게 요구하지 않는다.   
fd_set형 변수에 값을 등록하거나 변경하는 등의 작업은 다음 매크로 함수들의 도움을 통해서 이뤄진다.   
   
- FD_ZERO(fd_set* fdset) : 인자로 전달된 주소의 fd_set형 변수의 모든 비트를 0으로 초기화한다.
- FD_SET(int fd, fd_set* fdset) : 매개변수 fdset으로 전달된 주소의 변수에 매개변수 fd로 전달된 파일 디스크립터 정보를 등록한다.
- FD_CLR(int fd, fd_set* fdset) : 매개변수 fdset으로 전달된 주소의 변수에서 매개변수 fd로 전달된 파일 디스크립터 정보를 삭제한다.
- FD_ISSET(int fd, fd_set* fdset) : 매개변수 fdset으로 전달된 주소의 변수에 매개변수 fd로 전달된 파일 디스크립터 정보가 있으면 양수를 반환한다.   
   
위의 매크로 함수들 중에서 FD_ISSET은 select 함수의 호출 결과를 확인하는 용도로 사용된다.   
다음 그림은 위 함수들의 기능을 정리한 것이다.   
   
![fd_set 관련 함수의 기능](https://user-images.githubusercontent.com/46395776/98674941-e93ea800-239c-11eb-9c4b-ec92b916c6fc.jpeg)   
   
### 검사(관찰)의 범위 지정과 타임아웃의 설정   

다음은 select 함수를 보인다.   
   
`int select(int maxfd, fd_set* readset, fd_set* writeset, fd_set* exceptset, const struct timeval* timeout);`   

- maxfd : 검사 대상이 되는 파일 디스크립터의 수.
- readset : fd_set형 변수에 `수신된 데이터의 존재여부`에 관심 있는 파일 디스크립터 정보를 모두 등록해서 그 변수의 주소 값을 전달한다.
- writeset : fd_set형 변수에 `블로킹 없는 데이터 전송의 가능여부`에 관심 있는 파일 디스크립터 정보를 모두 등록해서 그 변수의 주소 값을 전달한다.
- exceptset : fd_set형 변수에 `예외상황의 발생여부`에 관심 있는 파일 디스크립터 정보를 모두 등록해서 그 변수의 주소 값을 전달한다.
- timeout : select 함수 호출 이후에 무한정 블로킹 상태에 빠지지 않도록 타임아웃(time-out)을 설정하기 위한 인자를 전달한다.
- 반환 값 : 오류 발생 시에는 -1이 반환되고, 타임 아웃에 의한 반환 시에는 0이 반환된다. 그리고 관심 대상으로 등록된 파일 디스크립터에 해당 관심에 관련된 변화가 발생하면 0보다 큰 값이 반환되는데, 이 값은 변화가 발생한 파일 디스크립터의 수를 의미한다.   
   
select 함수는 세 가지 관찰항목의 변화를 확인하는데 사용된다고 하지 않았는가?   
바로 이 세 가지 관찰항목별로 fd_set형 변수를 선언해서 파일 디스크립터 정보를 등록하고, 이 변수의 주소 값을 위 함수의 2, 3, 4번째 인자로 전달하게 된다.   
그런데 이에 앞서(select 함수의 호출에 앞서) 다음 두 가지를 먼저 결정해야 한다.   
   
- 파일 디스크립터의 관찰(검사) 범위는 어떻게 되지?
- select 함수의 타임아웃 시간을 어떻게 할까?   
   
이중 첫 번째, 파일 디스크립터의 관찰(검사) 범위는 select 함수의 첫 번째 매개변수와 관련이 있다.   
사실 select 함수는 관찰의 대상이 되는 파일 디스크립터의 수를 첫 번째 인자로 요구하고 있다.   
따라서 fd_set형 변수에 등록된 파일 디스크립터의 수를 확인할 필요가 있는데, 파일 디스크립터의 값은 생성될 때마다 1씩 증가하기 때문에 가장 큰 파일 디스크립터의 값에 1을 더해서 인자로 전달하면 된다.   
1을 더하는 이유는 파일 디스크립터의 값이 0에서부터 시작하기 때문이다.   
   
그리고 두 번째, select 함수의 타임아웃 시간은 select 함수의 마지막 매개변수와 관련이 있는데, 매개변수 선언에서 보이는 자료형 timeval은 구조체 기반의 자료형으로, 다음과 같이 정의되어있다.   
   
<pre>
<code>

struct timeval
{
	long tv_sec;	// seconds
	long tv_usec;	// microseconds
}

</code>
</pre>   
   
원래 select 함수는 관찰 중인 파일 디스크립터에 변화가 생겨야 반환을 한다.   
때문에 `변화가 생기지 않으면 무한정 블로킹 상태`에 머물게 된다.   
바로 이러한 상황을 막기 위해서 타임아웃을 지정하는 것이다.   
위 구조체 변수를 선언해서 멤버 tv_sec에 초 단위 정보를, 멤버 tv_usec에 마이크로 초 단위 정보를 지정하고, 이 변수의 주소 값을 select 함수의 마지막 인자로 전달하면, 파일 디스크립터에 변화가 발생하지 않아도 지정된 시간이 지나면 함수가 반환을 한다.   
단! 이렇게 해서 반환이 되는 경우, select 함수는 0을 반환한다.   
때문에 반환 값을 통해서 반환의 원인을 알 수 있다.   
그리고 타임아웃을 설정하고 싶지 않은 경우에는 NULL을 인자로 전달하면 된다.   

### select 함수호출 이후의 결과 확인   

select 함수가 0이 아닌 양수를 반환하면, 그 수만큼 파일 디스크립터에 변화가 발생했음을 의미한다.   
그렇다면 select 함수가 양의 정수를 반환한 경우, 변화가 발생한 파일 디스크립터는 어떻게 알아낼 수 있을까?   
select 함수의 2, 3, 4번째 인자로 전달된 fd_set형 변수에 다음 그림에서 보이는 변화가 발생하기 때문에 어렵지 않게 알아낼 수 있다.   
   
![fd_set형 변수의 변화](https://user-images.githubusercontent.com/46395776/98677793-e3e35c80-23a0-11eb-9ebd-3bc92a82a1f7.png)   
   
위 그림에서 보이듯이 select 함수 호출이 완료되고 나면, select 함수의 인자로 전달된 fd_set형 변수에는 변화가 생긴다.   
1로 설정된 모든 비트가 다 0으로 변경되지만, 변화가 발생한 파일 디스크립터에 해당하는 비트만 그대로 1로 남아있게 된다.   
때문에 여전히 1로 남아있는 위치의 파일 디스크립터에서 변화가 발생했다고 판단할 수 있다.   
   
   
   #
# 멀티캐스트(Multicast)   

### 멀티캐스트의 데이터 전송방식과 멀티캐스트 트래픽 이점   

우리가 인터넷 방송국을 운영하고 있다고 가정해 보자.   
그렇다면 우리는 가입자들에게 멀티미디어 정보를 전송해야 한다.   
만약에 가입자 중 1,000명이 서비스를 요청한다면 1,000명에게, 10,000명이 서비스를 요청한다면 10,000명에게 데이터를 전송해줘야 한다.   
이 상황에서 TCP를 기반으로 서비스를 제공한다면 1,000개 또는 10,000개에 해당하는 소켓 연결을 유지해야 하고, UDP 소켓을 기반으로 서비스를 제공하더라도 1,000회 또는 10,000회의 데이터 전송이 필요하다.   
이렇듯 다수의 클라이언트에게 동일한 데이터를 전송하는 일 조차 서버와 네트워크의 트래픽 측면에서는 매우 부정적이다.   
그러나 이러한 상황에서의 해결책으로 `멀티캐스트`라는 기술이 존재한다.   
   
멀티캐스트 방식의 데이터 전송은 UDP를 기반으로 한다.   
따라서 UDP 서버 / 클라이언트의 구현 방식과 매우 유사하다.   
차이점이 있다면 UDP에서의 데이터 전송은 하나의 목적지를 두고 이뤄지지만 멀티캐스트에서의 데이터 전송은 특정 그룹에 가입(등록)되어 있는 다수의 호스트가 된다는 점이다.   
즉, 멀티캐스트 방식을 이용하면 단 한 번의 데이터 전송으로 다수의 호스트에게 데이터를 전송할 수 있다.   
   
멀티캐스트의 데이터 전송 특성은 다음과 같이 간단히 정리할 수 있다.   
   
- 멀티캐스트 서버는 특정 멀티캐스트 그룹을 대상으로 데이터를 딱 한 번 전송한다.
- 딱! 한 번 전송하더라도 그룹에 속하는 클라이언트는 모두 데이터를 수신한다.
- 멀티캐스트 그룹의 수는 IP 주소 범위 내에서 얼마든지 추가가 가능하다.
- 특정 멀티캐스트 그룹으로 전송되는 데이터를 수신하려면 해당 그룹에 가입하면 된다.   
   
여기서 말하는 멀티캐스트 그룹이란 클래스 D에 속하는 IP 주소(244.0.0.0 ~ 239.255.255.255)를 가리킨다.   
따라서 멀티캐스트 그룹에 가입을 한다는 것은 프로그램 코드 상에서 다음과 같이 말하는 것 정도로 이해할 수 있다.   
   
- 나는 클래스 D에 속하는 IP 주소 중에서 239.234.218.234를 목적지로 전송되는 멀티캐스트 데이터에 관심이 있으므로, 이 데이터를 수신하겠다.   
   
멀티캐스트는 UDP를 기반으로 한다고 하였다.   
즉, 멀티캐스트 패킷은 그 형태가 UDP 패킷과 동일하다.   
다만 일반적인 UDP 패킷과 달리 하나의 패킷만 네트워크상에 띄워 놓으면 라우터들은 이 패킷을 복사해서 다수의 호스트에 이를 전달한다.   
이렇듯 멀티캐스트는 다음 그림에서 보이듯이 라우터의 도움으로 완성된다.   
   
![멀티캐스트 라우팅](https://user-images.githubusercontent.com/46395776/99144042-ec3fde00-26a5-11eb-83e4-2f168cc1b955.png)   
   
위 그림은 특정 멀티캐스트 그룹으로 전송된 하나의 멀티캐스트 패킷이 라우터들의 도움으로 해당 멀티캐스트 그룹에 가입한 모든 호스트에 전송되는 과정을 보이고 있다.   
트래픽 측면에서는 부정적으로 보이는가?   
하지만 위에서 다수의 클라이언트에게 동일한 데이터를 전송하는 일 조차 서버와 네트워크의 트래픽 측면에서 매우 부정적이지만, 이러한 상황에서의 해결책으로 멀티캐스트라는 기술이 존재한다고 언급했다.   
위 그림을 단순히 보면 트래픽에 부정적이라 생각할 수 있다.   
왜냐하면 하나의 패킷이 여러 라우터를 통해서 빈번히 복사되기 때문이다.   
하지만 `하나의 영역에 동일한 패킷이 둘 이상 전송되지 않는다!`는 사실을 관찰하자.   
   
만약에 TCP 또는 UDP 방식으로 1,000개의 호스트에 파일을 전송하려면, 총 1,000회 파일을 전송해야 한다.   
열 개의 호스트가 하나의 네트워크로 묶여 있어서 경로의 99%가 일치하더라도 말이다.   
하지만 이러한 경우에 멀티캐스트 방식으로 파일을 전송하면 딱 한 번만 전송해주면 된다.   
1,000개의 호스트를 묶고 있는 라우터가 1,000개의 호스트에게 파일을 복사해 줄 테니 말이다.   
바로 이러한 성격 때문에 멀티캐스트 방식의 데이터 전송은 `멀티미디어 데이터의 실시간 전송`에 주로 사용된다.   
   
참고로 위 그림에서 보이듯이 이론상으로는 쉽게 멀티캐스팅이 가능해야 하지만, 아직도 적지 않은 수의 라우터가 멀티캐스트를 지원하지 않거나 지원하더라도 네트워크의 불필요한 트래픽 문제를 고려해서 일부러 막아 놓은 경우가 많다.   
때문에 멀티캐스트를 지원하지 않는 라우터를 거쳐서 멀티캐스트 패킷을 전송하기 위한 `터널링(Tunneling)` 기술이라는 것도 사용된다(이는 멀티캐스트 기반의 응용 프로그램 개발자가 고민할 문제는 아니다).   
어찌되었든 여기서는 멀티캐스트 서비스가 가능한 환경이 구축되어 있는 상황에서의 프로그래밍 방법에 대해서만 이야기한다.   

### 라우팅(Routing)과 TTL(Time to Live), 그리고 그룹으로의 가입 방법   

멀티캐스트 패킷의 전송을 위해서는 `TTL`이라는 것의 설정 과정을 반드시 거쳐야 한다.   
TTL이란 Time to Live의 약자로써 `패킷을 얼마나 멀리 전달할 것인가`를 결정하는 주 요소가 된다.   
TTL은 정수로 표현되며, 이 값은 라우터를 하나 거칠 때마다 1씩 감소한다.   
그리고 이 값이 0이 되면 패킷은 더 이상 전달되지 못하고 소멸된다.   
따라서 TTL을 너무 크게 설정하면 네트워크 트래픽에 좋지 못한 영향을 줄 수 있다.   
물론, 너무 적게 설정해도 목적지에 도달하지 않는 문제가 발생할 수 있으니 주의해야 한다.   
   
![멀티캐스트 TTL](https://user-images.githubusercontent.com/46395776/99144639-dbde3200-26aa-11eb-991c-bd50d61e22eb.png)   
   
다음은 TTL의 설정 방법이다.   
프로그램상에서의 TTL 설정은 `소켓의 옵션설정`을 통해 이뤄진다.   
TTL의 설정과 관련된 프로토콜의 레벨은 `IPPROTO_IP`이고, 옵션의 이름은 `IP_MULTICAST_TTL`이다.   
따라서 TTL을 64로 설정하고자 할 때에는 다음과 같이 코드를 구성하면 된다.   
   
<pre>
<code>

int send_sock;
int time_live = 64;
. . . .
send_sock = socket(PF_INET, SOCK_DGRAM, 0);
setsockopt(send_sock, IPPROTO_IP, IP_MULTICAST_TTL, (void*)&time_live, sizeof(time_live));
. . . .

</code>
</pre>   
   
그리고 멀티캐스트 그룹으로의 가입 역시 소켓의 옵션설정을 통해 이뤄진다.   
그룹 가입과 관련된 프로토콜의 레벨은 `IPPROTO_IP`이고, 옵션의 이름은 `IP_ADD_MEMBERSHIP`이다.   
따라서 그룹의 가입은 다음과 같이 진행된다.   
   
<pre>
<code>

int recv_sock;
struct ip_mreq join_adr;
. . . .
recv_sock = socket(PF_INET, SOCK_DGRAM, 0);
. . . .
join_adr.imr_multiaddr.s_addr = "멀티캐스트 그룹의 주소 정보";
join_adr.imr_interface.s_addr = "그룹에 가입할 호스트의 주소 정보";
setsockopt(recv_sock, IPPROTO_IP, IP_ADD_MEMBERSHIP, (void*)&join_adr, sizeof(join_adr));
. . . .

</code>
</pre>   
   
위의 코드에서 보인 구조체 `ip_mreq`에 대해서 설명한다. 이 구조체는 다음과 같이 정의되어 있다.   
   
<pre>
<code>

struct ip_mreq
{
	struct in_addr imr_multiaddr;
	struct in_addr imr_interface;
}

</code>
</pre>   
   
우선 첫 번째 멤버 `imr_multiaddr`에는 가입할 그룹의 IP 주소를 채워 넣는다.   
그리고 두 번째 멤버인 `imt_interface`에는 그룹에 가입하는 소켓이 속한 호스트의 IP 주소를 명시하는데, `INADDR_ANY`를 이용하는 것도 가능하다.   
   
   
   #
# 브로드캐스트(Broadcast)   

### 브로드캐스트의 이해와 구현 방법   

이번에 소개하는 브로드캐스트는 한 번에 여러 호스트에게 데이터를 전송한다는 점에서 멀티캐스트와 유사하다.   
그러나 전송이 이뤄지는 범위에서 차이가 난다.   
멀티캐스트는 서로 다른 네트워크상에 존재하는 호스트라 할지라도, 멀티캐스트 그룹에 가입만 되어 있으면 데이터의 수신이 가능하다.   
반면 브로드캐스트는 동일한 네트워크로 연결되어 있는 호스트로, 데이터의 전송 대상이 제한된다.   
   
브로드캐스트는 동일한 네트워크에 연결되어 있는 모든 호스트에게 동시에 데이터를 전송하기 위한 방법이다.   
이 역시 멀티캐스트와 마찬가지로 UDP를 기반으로 데이터를 송수신한다.   
그리고 데이터 전송 시 사용되는 IP 주소의 형태에 따라서 다음과 같이 두 가지 형태로 구분이 된다.   
   
- Directed 브로드캐스트(Broadcast)
- Local 브로드캐스트(Broadcast)   
   
코드상에서 확인되는 이 둘의 차이점은 IP 주소에 있다.   
Directed 브로드캐스트의 IP 주소는 네트워크 주소를 제외한 나머지 호스트 주소를 전부 1로 설정해서 얻을 수 있다.   
예를 들어서 네트워크 주소가 193.12.34인 네트워크에 연결되어 있는 모든 호스트에게 데이터를 전송하려면 192.12.34.255로 데이터를 전송하면 된다.   
이렇듯 특정 지역의 네트워크에 연결된 모든 호스트에게 데이터를 전송하려면 Directed 브로드캐스트 방식으로 데이터를 전송하면 된다.   
   
반면 Local 브로드캐스트를 위해서는 `255.255.255.255`라는 IP 주소가 특별히 예약되어 있다.   
예를 들어서 네트워크 주소가 192.32.24인 네트워크에 연결되어 있는 호스트가 IP 주소 255.255.255.255를 대상으로 데이터를 전송하면, 192.32.24로 시작하는 IP 주소의 모든 호스트에게 데이터가 전달된다.   
   
그렇다면 브로드캐스트 Sender와 Receiver는 어떻게 구현해야 할까?   
사실 브로드캐스트 예제는 데이터 송수신에 사용되는 IP 주소를 유심히 관찰하지 않으면, UDP 예제와 잘 구분이 안 된다.   
즉, 데이터 송수신에 사용되는 IP 주소가 UDP 예제와의 유일한 차이점이다.   
다만 기본적으로 생성되는 소켓은 브로드캐스트 기반의 데이터 전송이 불가능하도록 설정되어 있기 때문에 다음 유형의 코드 구성을 통해서 이를 변경할 필요는 있다.   
   
<pre>
<code>

int send_sock;
int bcast = 1;	// SO_BROADCAST의 옵션 정보를 1로 변경하기 위한 변수 초기화
. . . .
send_sock = socket(PF_INET, SOCK_DGRAM, 0);
. . . .
setsockopt(send_sock, SOL_SOCKET, SO_BROADCAST, (void*)&bcast, sizeof(bcast));
. . . .

</code>
</pre>   
   
위의 setsockopt 함수 호출을 통해서 SO_BROADCAST의 옵션 정보를 변수 bcast에 저장된 값인 1로 변경하는데, 이는 브로드캐스트 기반의 데이터 전송이 가능함을 의미한다.   
물론 위에서 보인 소켓옵션의 변경은 데이터를 전송하는 Sender에나 필요할 뿐, Receiver의 구현에서는 필요가 없다.